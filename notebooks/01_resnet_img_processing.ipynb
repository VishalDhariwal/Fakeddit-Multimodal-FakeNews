{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1e8mv0bCCNny"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.read_csv('/content/drive/MyDrive/multimodal_train.tsv',delimiter='\\t')\n",
        "df_test = pd.read_csv('/content/drive/MyDrive/multimodal_test_public.tsv',delimiter='\\t')"
      ],
      "metadata": {
        "id": "jaIMbvmRCkEM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWrgornUC_un",
        "outputId": "5d8031b0-c500-4039-8a54-c3df2063519b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(564000, 16)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Yqe2EbvDC6E",
        "outputId": "8f85b01e-6052-4e5e-d331-f5b086d98bda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(59319, 16)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = df_train.iloc[:205000, ]"
      ],
      "metadata": {
        "id": "i4G5u0LDDHGZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "YXutu4RyGHnn",
        "outputId": "94a3910d-c97c-4718-e6ac-eb943071c9ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           author                                        clean_title  \\\n",
              "0     Alexithymia  my walgreens offbrand mucinex was engraved wit...   \n",
              "1        VIDCAs17                this concerned sink with a tiny hat   \n",
              "2  prometheus1123      hackers leak emails from uae ambassador to us   \n",
              "3             NaN                           puppy taking in the view   \n",
              "4       3rikR3ith               i found a face in my sheet music too   \n",
              "\n",
              "    created_utc         domain  hasImage      id  \\\n",
              "0  1.551641e+09    i.imgur.com      True  awxhir   \n",
              "1  1.534727e+09      i.redd.it      True  98pbid   \n",
              "2  1.496511e+09  aljazeera.com      True  6f2cy5   \n",
              "3  1.471341e+09    i.imgur.com      True  4xypkv   \n",
              "4  1.525318e+09      i.redd.it      True  8gnet9   \n",
              "\n",
              "                                           image_url linked_submission_id  \\\n",
              "0  https://external-preview.redd.it/WylDbZrnbvZdB...                  NaN   \n",
              "1  https://preview.redd.it/wsfx0gp0f5h11.jpg?widt...                  NaN   \n",
              "2  https://external-preview.redd.it/6fNhdbc6K1vFA...                  NaN   \n",
              "3  https://external-preview.redd.it/HLtVNhTR6wtYt...                  NaN   \n",
              "4  https://preview.redd.it/ri7ut2wn8kv01.jpg?widt...                  NaN   \n",
              "\n",
              "   num_comments  score          subreddit  \\\n",
              "0           2.0     12  mildlyinteresting   \n",
              "1           2.0    119         pareidolia   \n",
              "2           1.0     44        neutralnews   \n",
              "3          26.0    250   photoshopbattles   \n",
              "4           2.0     13         pareidolia   \n",
              "\n",
              "                                               title  upvote_ratio  \\\n",
              "0  My Walgreens offbrand Mucinex was engraved wit...          0.84   \n",
              "1                This concerned sink with a tiny hat          0.99   \n",
              "2      Hackers leak emails from UAE ambassador to US          0.92   \n",
              "3                 PsBattle: Puppy taking in the view          0.95   \n",
              "4              I found a face in my sheet music too!          0.84   \n",
              "\n",
              "   2_way_label  3_way_label  6_way_label  \n",
              "0            1            0            0  \n",
              "1            0            2            2  \n",
              "2            1            0            0  \n",
              "3            1            0            0  \n",
              "4            0            2            2  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-486a75ed-5bf9-4d03-94e9-a2708dd6d4f8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>author</th>\n",
              "      <th>clean_title</th>\n",
              "      <th>created_utc</th>\n",
              "      <th>domain</th>\n",
              "      <th>hasImage</th>\n",
              "      <th>id</th>\n",
              "      <th>image_url</th>\n",
              "      <th>linked_submission_id</th>\n",
              "      <th>num_comments</th>\n",
              "      <th>score</th>\n",
              "      <th>subreddit</th>\n",
              "      <th>title</th>\n",
              "      <th>upvote_ratio</th>\n",
              "      <th>2_way_label</th>\n",
              "      <th>3_way_label</th>\n",
              "      <th>6_way_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Alexithymia</td>\n",
              "      <td>my walgreens offbrand mucinex was engraved wit...</td>\n",
              "      <td>1.551641e+09</td>\n",
              "      <td>i.imgur.com</td>\n",
              "      <td>True</td>\n",
              "      <td>awxhir</td>\n",
              "      <td>https://external-preview.redd.it/WylDbZrnbvZdB...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>12</td>\n",
              "      <td>mildlyinteresting</td>\n",
              "      <td>My Walgreens offbrand Mucinex was engraved wit...</td>\n",
              "      <td>0.84</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>VIDCAs17</td>\n",
              "      <td>this concerned sink with a tiny hat</td>\n",
              "      <td>1.534727e+09</td>\n",
              "      <td>i.redd.it</td>\n",
              "      <td>True</td>\n",
              "      <td>98pbid</td>\n",
              "      <td>https://preview.redd.it/wsfx0gp0f5h11.jpg?widt...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>119</td>\n",
              "      <td>pareidolia</td>\n",
              "      <td>This concerned sink with a tiny hat</td>\n",
              "      <td>0.99</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>prometheus1123</td>\n",
              "      <td>hackers leak emails from uae ambassador to us</td>\n",
              "      <td>1.496511e+09</td>\n",
              "      <td>aljazeera.com</td>\n",
              "      <td>True</td>\n",
              "      <td>6f2cy5</td>\n",
              "      <td>https://external-preview.redd.it/6fNhdbc6K1vFA...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>44</td>\n",
              "      <td>neutralnews</td>\n",
              "      <td>Hackers leak emails from UAE ambassador to US</td>\n",
              "      <td>0.92</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>puppy taking in the view</td>\n",
              "      <td>1.471341e+09</td>\n",
              "      <td>i.imgur.com</td>\n",
              "      <td>True</td>\n",
              "      <td>4xypkv</td>\n",
              "      <td>https://external-preview.redd.it/HLtVNhTR6wtYt...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>26.0</td>\n",
              "      <td>250</td>\n",
              "      <td>photoshopbattles</td>\n",
              "      <td>PsBattle: Puppy taking in the view</td>\n",
              "      <td>0.95</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3rikR3ith</td>\n",
              "      <td>i found a face in my sheet music too</td>\n",
              "      <td>1.525318e+09</td>\n",
              "      <td>i.redd.it</td>\n",
              "      <td>True</td>\n",
              "      <td>8gnet9</td>\n",
              "      <td>https://preview.redd.it/ri7ut2wn8kv01.jpg?widt...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>13</td>\n",
              "      <td>pareidolia</td>\n",
              "      <td>I found a face in my sheet music too!</td>\n",
              "      <td>0.84</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-486a75ed-5bf9-4d03-94e9-a2708dd6d4f8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-486a75ed-5bf9-4d03-94e9-a2708dd6d4f8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-486a75ed-5bf9-4d03-94e9-a2708dd6d4f8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-cfb92fae-23d3-4d6e-adaf-643ba4a891fb\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cfb92fae-23d3-4d6e-adaf-643ba4a891fb')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-cfb92fae-23d3-4d6e-adaf-643ba4a891fb button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_train"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the path and filename in your Google Drive\n",
        "save_path = '/content/drive/MyDrive/image_embeddings_train_real.npy'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GAfrHMSyHBmr",
        "outputId": "e597d30d-767a-40c9-e90b-f3aa6f1dde18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import requests\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "from tqdm import tqdm\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from torchvision import transforms\n",
        "from google.colab import drive\n",
        "\n",
        "# --- 1. Model and Preprocessing Setup ---\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\n",
        "feature_extractor = torch.nn.Sequential(*list(model.children())[:-1])\n",
        "feature_extractor.to(device)\n",
        "feature_extractor.eval()\n",
        "\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# --- 2. Processing Function ---\n",
        "def download_and_preprocess_image(data):\n",
        "    index, url = data\n",
        "    try:\n",
        "        response = requests.get(url, timeout=10)\n",
        "        response.raise_for_status()\n",
        "        img = Image.open(BytesIO(response.content)).convert('RGB')\n",
        "        tensor = preprocess(img)\n",
        "        return index, tensor\n",
        "    except Exception as e:\n",
        "        return index, None\n",
        "\n",
        "# --- 3. Main Feature Extraction Loop ---\n",
        "urls = df_train['image_url'].tolist()\n",
        "url_data = list(zip(df_train.index, urls))\n",
        "batch_size = 64\n",
        "all_features = []\n",
        "successful_indices = []\n",
        "\n",
        "with ThreadPoolExecutor(max_workers=16) as executor:\n",
        "    results_gen = executor.map(download_and_preprocess_image, url_data)\n",
        "    batch = []\n",
        "    for index, tensor in tqdm(results_gen, total=len(urls), desc=\"Processing images\"):\n",
        "        if tensor is not None:\n",
        "            successful_indices.append(index)\n",
        "            batch.append(tensor)\n",
        "\n",
        "        if len(batch) == batch_size:\n",
        "            input_batch = torch.stack(batch).to(device)\n",
        "            with torch.no_grad():\n",
        "                features = feature_extractor(input_batch)\n",
        "            all_features.append(features.squeeze().cpu().numpy())\n",
        "            batch = []\n",
        "\n",
        "    if len(batch) > 0:\n",
        "        input_batch = torch.stack(batch).to(device)\n",
        "        with torch.no_grad():\n",
        "            features = feature_extractor(input_batch)\n",
        "        all_features.append(features.squeeze().cpu().numpy())\n",
        "\n",
        "# --- 4. Final Alignment, Verification, and Saving ---\n",
        "X_img = np.vstack(all_features)\n",
        "df_train_clean = df_train.loc[successful_indices]\n",
        "\n",
        "print(\"\\n--- Verification ---\")\n",
        "print(f\"Original DataFrame shape: {df_train.shape}\")\n",
        "print(f\"Cleaned DataFrame shape:  {df_train_clean.shape}\")\n",
        "print(f\"Image features shape:     {X_img.shape}\")\n",
        "\n",
        "# Mount drive, define path, and save\n",
        "\n",
        "np.save(save_path, X_img)\n",
        "\n",
        "print(f\"\\n✅ Embeddings saved successfully to {save_path}\")\n",
        "print(f\"Shape of saved array: {X_img.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjou41wEF9p2",
        "outputId": "492c9a2a-7553-4702-9f44-73ce64af08cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n",
            "Processing images:   3%|▎         | 5841/205000 [00:26<13:11, 251.47it/s]/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "Processing images: 100%|██████████| 205000/205000 [14:08<00:00, 241.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Verification ---\n",
            "Original DataFrame shape: (205000, 16)\n",
            "Cleaned DataFrame shape:  (58487, 16)\n",
            "Image features shape:     (58487, 512)\n",
            "\n",
            "✅ Embeddings saved successfully to /content/drive/MyDrive/image_embeddings_train_real.npy\n",
            "Shape of saved array: (58487, 512)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import requests\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "from tqdm import tqdm\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from torchvision import transforms\n",
        "from google.colab import drive\n",
        "\n",
        "# --- 1. Model and Preprocessing Setup (Run this cell once) ---\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\n",
        "feature_extractor = torch.nn.Sequential(*list(model.children())[:-1])\n",
        "feature_extractor.to(device)\n",
        "feature_extractor.eval()\n",
        "\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# --- 2. The Reusable Feature Extraction Function (Run this cell once) ---\n",
        "\n",
        "# Helper function now with a timeout parameter\n",
        "def _download_and_preprocess_image(data, timeout):\n",
        "    index, url = data\n",
        "    try:\n",
        "        # The timeout is now passed into the request\n",
        "        response = requests.get(url, timeout=timeout)\n",
        "        response.raise_for_status()\n",
        "        img = Image.open(BytesIO(response.content)).convert('RGB')\n",
        "        tensor = preprocess(img)\n",
        "        return index, tensor\n",
        "    except Exception as e:\n",
        "        return index, None\n",
        "\n",
        "def extract_image_features(df, timeout_seconds=20):\n",
        "    \"\"\"\n",
        "    Processes a DataFrame to extract image features from a URL column.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): The DataFrame to process (e.g., df_train or df_test).\n",
        "                           It must have a column named 'image_url'.\n",
        "        timeout_seconds (int): The number of seconds to wait for a server response.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing:\n",
        "            - df_clean (pd.DataFrame): The filtered DataFrame with only successful rows.\n",
        "            - X_img (np.ndarray): The NumPy array of corresponding image features.\n",
        "    \"\"\"\n",
        "    print(f\"\\nProcessing {len(df)} URLs with a {timeout_seconds}-second timeout...\")\n",
        "\n",
        "    urls = df['image_url'].tolist()\n",
        "    url_data = list(zip(df.index, urls))\n",
        "\n",
        "    batch_size = 64\n",
        "    all_features = []\n",
        "    successful_indices = []\n",
        "\n",
        "    # We use a lambda to pass the timeout argument to our helper function\n",
        "    func = lambda data: _download_and_preprocess_image(data, timeout=timeout_seconds)\n",
        "\n",
        "    with ThreadPoolExecutor(max_workers=16) as executor:\n",
        "        results_gen = executor.map(func, url_data)\n",
        "        batch = []\n",
        "        for index, tensor in tqdm(results_gen, total=len(urls), desc=\"Processing images\"):\n",
        "            if tensor is not None:\n",
        "                successful_indices.append(index)\n",
        "                batch.append(tensor)\n",
        "\n",
        "            if len(batch) == batch_size:\n",
        "                input_batch = torch.stack(batch).to(device)\n",
        "                with torch.no_grad():\n",
        "                    features = feature_extractor(input_batch)\n",
        "                all_features.append(features.squeeze().cpu().numpy())\n",
        "                batch = []\n",
        "\n",
        "        if len(batch) > 0:\n",
        "            input_batch = torch.stack(batch).to(device)\n",
        "            with torch.no_grad():\n",
        "                features = feature_extractor(input_batch)\n",
        "            all_features.append(features.squeeze().cpu().numpy())\n",
        "\n",
        "    if not all_features:\n",
        "        print(\"Warning: No images were processed successfully.\")\n",
        "        return pd.DataFrame(), np.array([])\n",
        "\n",
        "    X_img = np.vstack(all_features)\n",
        "    df_clean = df.loc[successful_indices]\n",
        "\n",
        "    print(\"\\n--- Verification ---\")\n",
        "    print(f\"Original DataFrame shape: {df.shape}\")\n",
        "    print(f\"Cleaned DataFrame shape:  {df_clean.shape}\")\n",
        "    print(f\"Image features shape:     {X_img.shape}\")\n",
        "\n",
        "    return df_clean, X_img\n",
        "\n",
        "\n",
        "# --- 3. How to Use for Both df_train and df_test ---\n",
        "\n",
        "# Process the training data\n",
        "df_train_clean, X_img_train = extract_image_features(df_train, timeout_seconds=20)\n",
        "\n",
        "# Process the testing data\n",
        "df_test_clean, X_img_test = extract_image_features(df_test, timeout_seconds=20)\n",
        "\n",
        "\n",
        "# --- 4. Save the Results ---\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Save training results\n",
        "np.save('/content/drive/MyDrive/X_img_train.npy', X_img_train)\n",
        "df_train_clean.to_csv('/content/drive/MyDrive/df_train_clean.csv', index=False)\n",
        "print(\"\\n✅ Training data and features saved successfully.\")\n",
        "\n",
        "# Save testing results\n",
        "np.save('/content/drive/MyDrive/X_img_embeddings_test.npy', X_img_test)\n",
        "df_test_clean.to_csv('/content/drive/MyDrive/df_test_clean.csv', index=False)\n",
        "print(\"✅ Testing data and features saved successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93syjRSWRwaM",
        "outputId": "a6973f94-5ed0-4345-f38c-e79cb1e22d8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "\n",
            "Processing 59319 URLs with a 20-second timeout...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n",
            "Processing images:   2%|▏         | 1017/59319 [00:06<06:20, 153.22it/s]/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "Processing images: 100%|██████████| 59319/59319 [04:56<00:00, 199.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Verification ---\n",
            "Original DataFrame shape: (59319, 16)\n",
            "Cleaned DataFrame shape:  (20199, 16)\n",
            "Image features shape:     (20199, 512)\n",
            "✅ Testing data and features saved successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_half = pd.read_csv('/content/drive/MyDrive/multimodal_train.tsv', delimiter='\\t')"
      ],
      "metadata": {
        "id": "iQKuG7z1TZF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_half = df_train_half.iloc[205001:,]"
      ],
      "metadata": {
        "id": "OLcsH9FCTuKZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_half.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ViBpNWfNUMtl",
        "outputId": "93c5277a-5e0a-4f83-8962-d4ff3c6a1108"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(358999, 16)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import requests\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "from tqdm import tqdm\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from torchvision import transforms\n",
        "from google.colab import drive\n",
        "\n",
        "# --- 1. Model and Preprocessing Setup (Run this cell once) ---\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\n",
        "feature_extractor = torch.nn.Sequential(*list(model.children())[:-1])\n",
        "feature_extractor.to(device)\n",
        "feature_extractor.eval()\n",
        "\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# --- 2. The Reusable Feature Extraction Function (Run this cell once) ---\n",
        "\n",
        "# Helper function now with a timeout parameter\n",
        "def _download_and_preprocess_image(data, timeout):\n",
        "    index, url = data\n",
        "    try:\n",
        "        # The timeout is now passed into the request\n",
        "        response = requests.get(url, timeout=timeout)\n",
        "        response.raise_for_status()\n",
        "        img = Image.open(BytesIO(response.content)).convert('RGB')\n",
        "        tensor = preprocess(img)\n",
        "        return index, tensor\n",
        "    except Exception as e:\n",
        "        return index, None\n",
        "\n",
        "def extract_image_features(df, timeout_seconds=20):\n",
        "    \"\"\"\n",
        "    Processes a DataFrame to extract image features from a URL column.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): The DataFrame to process (e.g., df_train or df_test).\n",
        "                           It must have a column named 'image_url'.\n",
        "        timeout_seconds (int): The number of seconds to wait for a server response.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing:\n",
        "            - df_clean (pd.DataFrame): The filtered DataFrame with only successful rows.\n",
        "            - X_img (np.ndarray): The NumPy array of corresponding image features.\n",
        "    \"\"\"\n",
        "    print(f\"\\nProcessing {len(df)} URLs with a {timeout_seconds}-second timeout...\")\n",
        "\n",
        "    urls = df['image_url'].tolist()\n",
        "    url_data = list(zip(df.index, urls))\n",
        "\n",
        "    batch_size = 64\n",
        "    all_features = []\n",
        "    successful_indices = []\n",
        "\n",
        "    # We use a lambda to pass the timeout argument to our helper function\n",
        "    func = lambda data: _download_and_preprocess_image(data, timeout=timeout_seconds)\n",
        "\n",
        "    with ThreadPoolExecutor(max_workers=16) as executor:\n",
        "        results_gen = executor.map(func, url_data)\n",
        "        batch = []\n",
        "        for index, tensor in tqdm(results_gen, total=len(urls), desc=\"Processing images\"):\n",
        "            if tensor is not None:\n",
        "                successful_indices.append(index)\n",
        "                batch.append(tensor)\n",
        "\n",
        "            if len(batch) == batch_size:\n",
        "                input_batch = torch.stack(batch).to(device)\n",
        "                with torch.no_grad():\n",
        "                    features = feature_extractor(input_batch)\n",
        "                all_features.append(features.squeeze().cpu().numpy())\n",
        "                batch = []\n",
        "\n",
        "        if len(batch) > 0:\n",
        "            input_batch = torch.stack(batch).to(device)\n",
        "            with torch.no_grad():\n",
        "                features = feature_extractor(input_batch)\n",
        "            all_features.append(features.squeeze().cpu().numpy())\n",
        "\n",
        "    if not all_features:\n",
        "        print(\"Warning: No images were processed successfully.\")\n",
        "        return pd.DataFrame(), np.array([])\n",
        "\n",
        "    X_img = np.vstack(all_features)\n",
        "    df_clean = df.loc[successful_indices]\n",
        "\n",
        "    print(\"\\n--- Verification ---\")\n",
        "    print(f\"Original DataFrame shape: {df.shape}\")\n",
        "    print(f\"Cleaned DataFrame shape:  {df_clean.shape}\")\n",
        "    print(f\"Image features shape:     {X_img.shape}\")\n",
        "\n",
        "    return df_clean, X_img\n",
        "\n",
        "\n",
        "\n",
        "# Process the training data\n",
        "df_train__half_clean, X_img_half_train = extract_image_features(df_train_half, timeout_seconds=15)\n",
        "\n",
        "\n",
        "# Save training results\n",
        "np.save('/content/drive/MyDrive/X_img_half_train.npy', X_img_half_train)\n",
        "# df_train_clean.to_csv('/content/drive/MyDrive/df_train_clean.csv', index=False)\n",
        "print(\"\\n✅ Training data and features saved successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qg3bgtrYUPlL",
        "outputId": "3ca0d0c1-344d-4ae7-bfe7-ec5654756edd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing 358999 URLs with a 15-second timeout...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing images: 100%|██████████| 358999/358999 [26:56<00:00, 222.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Verification ---\n",
            "Original DataFrame shape: (358999, 16)\n",
            "Cleaned DataFrame shape:  (101342, 16)\n",
            "Image features shape:     (101342, 512)\n",
            "\n",
            "✅ Training data and features saved successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge the two DataFrames into one\n",
        "df_train_full = pd.concat([df_train_clean, df_train__half_clean], ignore_index=True)\n",
        "\n",
        "# Vertically stack the two NumPy arrays\n",
        "X_img_full = np.vstack((X_img, X_img_half_train))"
      ],
      "metadata": {
        "id": "e12Dr7ceca1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_full.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-LqvLwRhcmVt",
        "outputId": "0132e7db-ab1c-4e3a-8d9b-80a33ae229f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(159829, 16)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_img_full.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90srMo7rcq5H",
        "outputId": "6759dc8d-6b77-4a8f-c4c5-d935f30b3056"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(159829, 512)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "\n",
        "# 1. Mount Google Drive\n",
        "# This will prompt you for authorization.\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2. Define the path for your new folder\n",
        "folder_path = '/content/drive/MyDrive/multimodel_dataset_extracted'\n",
        "\n",
        "# 3. Create the folder\n",
        "# The 'exist_ok=True' argument prevents an error if the folder already exists.\n",
        "os.makedirs(folder_path, exist_ok=True)\n",
        "print(f\"Folder '{folder_path}' is ready.\")\n",
        "\n",
        "# 4. Define the full paths for your files\n",
        "df_save_path = os.path.join(folder_path, 'df_train_full.csv')\n",
        "x_img_save_path = os.path.join(folder_path, 'X_img_full.npy')\n",
        "\n",
        "# 5. Save the DataFrame and NumPy array\n",
        "# Assuming 'df_train_full' and 'X_img_full' are your variables\n",
        "df_train_full.to_csv(df_save_path, index=False)\n",
        "np.save(x_img_save_path, X_img_full)\n",
        "\n",
        "print(f\"\\n✅ DataFrame saved successfully to: {df_save_path}\")\n",
        "print(f\"✅ NumPy array saved successfully to: {x_img_save_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufKtEUsbdOjm",
        "outputId": "0a503275-8f36-460d-f409-44c3c240a240"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Folder '/content/drive/MyDrive/multimodel_dataset_extracted' is ready.\n",
            "\n",
            "✅ DataFrame saved successfully to: /content/drive/MyDrive/multimodel_dataset_extracted/df_train_full.csv\n",
            "✅ NumPy array saved successfully to: /content/drive/MyDrive/multimodel_dataset_extracted/X_img_full.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test_save_path = os.path.join(folder_path, 'df_test_clean.csv')\n",
        "x_img_test_save_path = os.path.join(folder_path, 'X_img_test.npy')\n",
        "\n",
        "# 4. Save the test DataFrame and NumPy array\n",
        "df_test_clean.to_csv(df_test_save_path, index=False)\n",
        "np.save(x_img_test_save_path, X_img_test)\n",
        "\n",
        "print(f\"✅ Test DataFrame saved successfully to: {df_test_save_path}\")\n",
        "print(f\"✅ Test NumPy array saved successfully to: {x_img_test_save_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAfgcP5TeUGS",
        "outputId": "42f12fd5-d4b7-414d-d044-3a5a079713fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Test DataFrame saved successfully to: /content/drive/MyDrive/multimodel_dataset_extracted/df_test_clean.csv\n",
            "✅ Test NumPy array saved successfully to: /content/drive/MyDrive/multimodel_dataset_extracted/X_img_test.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mock_dftest = pd.read_csv('/content/drive/MyDrive/multimodel_dataset_extracted/df_train_full.csv')"
      ],
      "metadata": {
        "id": "wfxkjSWrepVz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mock_dftest.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qK6zy0NLe0U4",
        "outputId": "4f708109-e3d5-41a3-af68-e76c893ae8a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(159829, 16)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from google.colab import drive\n",
        "\n",
        "# 1. Mount your Google Drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# 2. Define the path to your file\n",
        "file_path = '/content/drive/MyDrive/multimodel_dataset_extracted/X_img_test.npy'\n",
        "\n",
        "# 3. Load the NumPy array\n",
        "X_img_full = np.load(file_path)\n",
        "\n",
        "# 4. Print the shape to verify it's loaded correctly\n",
        "print(\"✅ Array loaded successfully!\")\n",
        "print(f\"Shape of the array: {X_img_full.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAMAXrEMfKav",
        "outputId": "15172174-67d5-4a29-d24d-d637c7bdb876"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Array loaded successfully!\n",
            "Shape of the array: (20199, 512)\n"
          ]
        }
      ]
    }
  ]
}