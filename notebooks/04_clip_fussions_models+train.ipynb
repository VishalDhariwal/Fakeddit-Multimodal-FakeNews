{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. img + text + tabular\n",
        "2. late fussion\n",
        "3. without tabluar\n",
        "4. different weights\n",
        "5. hybrid"
      ],
      "metadata": {
        "id": "1aRO602HUswD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tMCkLp5OzHla"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.read_csv('/content/drive/MyDrive/ML-Project/clip_embeddings_multimodal/df_train_clean.csv')\n",
        "df_test = pd.read_csv('/content/drive/MyDrive/ML-Project/clip_embeddings_multimodal/df_test_clean.csv')"
      ],
      "metadata": {
        "id": "LLZ4WLPCzbQE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "d80c440d-538b-40de-ecfa-dc4a1aaf5e27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'pd' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2147895777.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/ML-Project/clip_embeddings_multimodal/df_train_clean.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/ML-Project/clip_embeddings_multimodal/df_test_clean.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "deletecol = [\n",
        "    'author',\n",
        "    'clean_title',\n",
        "    'created_utc',\n",
        "    'domain',\n",
        "    'hasImage',\n",
        "    'id',\n",
        "    'image_url',\n",
        "    'linked_submission_id',\n",
        "    'subreddit',\n",
        "    'title',\n",
        "    '3_way_label',\n",
        "    '6_way_label'\n",
        "]\n",
        "df_train = df_train.drop(columns=deletecol, errors='ignore')\n",
        "df_test = df_test.drop(columns=deletecol, errors='ignore')\n"
      ],
      "metadata": {
        "id": "TK7z5xvKzvf0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.sample(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "Dh8GNgJ1z7Bp",
        "outputId": "331846a9-dad8-4000-d2b3-75e1a37c9308"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        num_comments  score  upvote_ratio  2_way_label\n",
              "73454            2.0     41          0.87            1\n",
              "140901           1.0     94          0.92            0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-01c3169a-5c20-46b5-863c-978c0b776b51\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_comments</th>\n",
              "      <th>score</th>\n",
              "      <th>upvote_ratio</th>\n",
              "      <th>2_way_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>73454</th>\n",
              "      <td>2.0</td>\n",
              "      <td>41</td>\n",
              "      <td>0.87</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140901</th>\n",
              "      <td>1.0</td>\n",
              "      <td>94</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-01c3169a-5c20-46b5-863c-978c0b776b51')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-01c3169a-5c20-46b5-863c-978c0b776b51 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-01c3169a-5c20-46b5-863c-978c0b776b51');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-fe4ab444-1c92-4a3e-b977-5f577903e7f1\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fe4ab444-1c92-4a3e-b977-5f577903e7f1')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-fe4ab444-1c92-4a3e-b977-5f577903e7f1 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df_train\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"num_comments\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7071067811865476,\n        \"min\": 1.0,\n        \"max\": 2.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          2.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 37,\n        \"min\": 41,\n        \"max\": 94,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          94,\n          41\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"upvote_ratio\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03535533905932741,\n        \"min\": 0.87,\n        \"max\": 0.92,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.92,\n          0.87\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"2_way_label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.sample(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "0OwXALlnz-t3",
        "outputId": "84f6035c-38cf-4187-db0e-19e9729e5322"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       num_comments  score  upvote_ratio  2_way_label\n",
              "6426            0.0      4          0.76            0\n",
              "11666           0.0      6          0.75            0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3975dc0b-3a30-41bf-b233-2fab7aa2ed95\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_comments</th>\n",
              "      <th>score</th>\n",
              "      <th>upvote_ratio</th>\n",
              "      <th>2_way_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6426</th>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11666</th>\n",
              "      <td>0.0</td>\n",
              "      <td>6</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3975dc0b-3a30-41bf-b233-2fab7aa2ed95')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3975dc0b-3a30-41bf-b233-2fab7aa2ed95 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3975dc0b-3a30-41bf-b233-2fab7aa2ed95');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-6af464fd-6e20-4397-8af4-1fd8f7789296\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6af464fd-6e20-4397-8af4-1fd8f7789296')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-6af464fd-6e20-4397-8af4-1fd8f7789296 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df_test\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"num_comments\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 4,\n        \"max\": 6,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"upvote_ratio\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.007071067811865481,\n        \"min\": 0.75,\n        \"max\": 0.76,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.75\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"2_way_label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "7fiFqBWe0ES-",
        "outputId": "50d9e42b-0132-45bc-aa69-f6783a71d5ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        num_comments          score   upvote_ratio    2_way_label\n",
              "count  157206.000000  160186.000000  157206.000000  160186.000000\n",
              "mean       13.677652     578.497971       0.860101       0.508540\n",
              "std        90.333628    4167.995990       0.108140       0.499929\n",
              "min         0.000000    -148.000000       0.500000       0.000000\n",
              "25%         1.000000       7.000000       0.790000       0.000000\n",
              "50%         3.000000      16.000000       0.880000       1.000000\n",
              "75%         6.000000      41.000000       0.950000       1.000000\n",
              "max      6912.000000  137179.000000       1.000000       1.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b0dee8e2-7d6e-4d95-a27d-5638dc723d39\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_comments</th>\n",
              "      <th>score</th>\n",
              "      <th>upvote_ratio</th>\n",
              "      <th>2_way_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>157206.000000</td>\n",
              "      <td>160186.000000</td>\n",
              "      <td>157206.000000</td>\n",
              "      <td>160186.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>13.677652</td>\n",
              "      <td>578.497971</td>\n",
              "      <td>0.860101</td>\n",
              "      <td>0.508540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>90.333628</td>\n",
              "      <td>4167.995990</td>\n",
              "      <td>0.108140</td>\n",
              "      <td>0.499929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>-148.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>0.790000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>0.880000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>6.000000</td>\n",
              "      <td>41.000000</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>6912.000000</td>\n",
              "      <td>137179.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b0dee8e2-7d6e-4d95-a27d-5638dc723d39')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b0dee8e2-7d6e-4d95-a27d-5638dc723d39 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b0dee8e2-7d6e-4d95-a27d-5638dc723d39');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-c463b373-735c-41ca-9674-62cfdffbcf7e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c463b373-735c-41ca-9674-62cfdffbcf7e')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-c463b373-735c-41ca-9674-62cfdffbcf7e button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df_train\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"num_comments\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 55278.504453212365,\n        \"min\": 0.0,\n        \"max\": 157206.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          13.677652252458557,\n          3.0,\n          157206.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 68757.11650328762,\n        \"min\": -148.0,\n        \"max\": 160186.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          578.4979711085863,\n          16.0,\n          160186.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"upvote_ratio\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 55580.457327423814,\n        \"min\": 0.10814007445817268,\n        \"max\": 157206.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.8601005050697809,\n          0.88,\n          157206.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"2_way_label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 56634.100968861625,\n        \"min\": 0.0,\n        \"max\": 160186.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.5085400721661069,\n          1.0,\n          0.49992862231261\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import PowerTransformer\n",
        "\n",
        "df_train['num_comments_scaled'] = np.log1p(df_train['num_comments'])\n",
        "df_test['num_comments_scaled'] = np.log1p(df_test['num_comments'])\n",
        "\n",
        "yeo = PowerTransformer(method='yeo-johnson')\n",
        "\n",
        "# Fit on training set\n",
        "df_train['score_scaled'] = yeo.fit_transform(df_train[['score']])\n",
        "\n",
        "# Apply same transformation to test set\n",
        "df_test['score_scaled'] = yeo.transform(df_test[['score']])\n",
        "\n"
      ],
      "metadata": {
        "id": "RHWkVyb-0nkJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "lafk-w2o1kTg",
        "outputId": "b865f96a-a276-41fd-b801-b05a0dc03a4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        num_comments          score   upvote_ratio    2_way_label  \\\n",
              "count  157206.000000  160186.000000  157206.000000  160186.000000   \n",
              "mean       13.677652     578.497971       0.860101       0.508540   \n",
              "std        90.333628    4167.995990       0.108140       0.499929   \n",
              "min         0.000000    -148.000000       0.500000       0.000000   \n",
              "25%         1.000000       7.000000       0.790000       0.000000   \n",
              "50%         3.000000      16.000000       0.880000       1.000000   \n",
              "75%         6.000000      41.000000       0.950000       1.000000   \n",
              "max      6912.000000  137179.000000       1.000000       1.000000   \n",
              "\n",
              "       num_comments_scaled  score_scaled  \n",
              "count        157206.000000  1.601860e+05  \n",
              "mean              1.379716  2.654788e-17  \n",
              "std               1.175374  1.000003e+00  \n",
              "min               0.000000 -2.177326e+02  \n",
              "25%               0.693147 -3.351125e-01  \n",
              "50%               1.386294 -2.088422e-01  \n",
              "75%               1.945910 -1.271329e-02  \n",
              "max               8.841159  9.044161e+00  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7ee8bcc1-0eb5-4249-bf79-849cc3e1787a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_comments</th>\n",
              "      <th>score</th>\n",
              "      <th>upvote_ratio</th>\n",
              "      <th>2_way_label</th>\n",
              "      <th>num_comments_scaled</th>\n",
              "      <th>score_scaled</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>157206.000000</td>\n",
              "      <td>160186.000000</td>\n",
              "      <td>157206.000000</td>\n",
              "      <td>160186.000000</td>\n",
              "      <td>157206.000000</td>\n",
              "      <td>1.601860e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>13.677652</td>\n",
              "      <td>578.497971</td>\n",
              "      <td>0.860101</td>\n",
              "      <td>0.508540</td>\n",
              "      <td>1.379716</td>\n",
              "      <td>2.654788e-17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>90.333628</td>\n",
              "      <td>4167.995990</td>\n",
              "      <td>0.108140</td>\n",
              "      <td>0.499929</td>\n",
              "      <td>1.175374</td>\n",
              "      <td>1.000003e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>-148.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-2.177326e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>0.790000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.693147</td>\n",
              "      <td>-3.351125e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>0.880000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.386294</td>\n",
              "      <td>-2.088422e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>6.000000</td>\n",
              "      <td>41.000000</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.945910</td>\n",
              "      <td>-1.271329e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>6912.000000</td>\n",
              "      <td>137179.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>8.841159</td>\n",
              "      <td>9.044161e+00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7ee8bcc1-0eb5-4249-bf79-849cc3e1787a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7ee8bcc1-0eb5-4249-bf79-849cc3e1787a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7ee8bcc1-0eb5-4249-bf79-849cc3e1787a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-4c915452-0b61-4fd0-ab31-ad94ed863af2\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4c915452-0b61-4fd0-ab31-ad94ed863af2')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-4c915452-0b61-4fd0-ab31-ad94ed863af2 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df_train\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"num_comments\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 55278.504453212365,\n        \"min\": 0.0,\n        \"max\": 157206.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          13.677652252458557,\n          3.0,\n          157206.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 68757.11650328762,\n        \"min\": -148.0,\n        \"max\": 160186.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          578.4979711085863,\n          16.0,\n          160186.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"upvote_ratio\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 55580.457327423814,\n        \"min\": 0.10814007445817268,\n        \"max\": 157206.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.8601005050697809,\n          0.88,\n          157206.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"2_way_label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 56634.100968861625,\n        \"min\": 0.0,\n        \"max\": 160186.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.5085400721661069,\n          1.0,\n          0.49992862231261\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"num_comments_scaled\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 55579.935482129,\n        \"min\": 0.0,\n        \"max\": 157206.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          1.3797162395162537,\n          1.3862943611198906,\n          157206.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score_scaled\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 56644.87346326166,\n        \"min\": -217.73257415205538,\n        \"max\": 160186.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          2.6547877302162484e-17,\n          -0.20884222335833214,\n          160186.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "sIqLybme1mdT",
        "outputId": "b6d5f18f-53f8-4f9e-b648-899387b8e46a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       num_comments          score  upvote_ratio   2_way_label  \\\n",
              "count  16352.000000   16696.000000  16352.000000  16696.000000   \n",
              "mean      14.679428     618.658840      0.860627      0.506049   \n",
              "std      158.367384    4407.505596      0.107915      0.499978   \n",
              "min        0.000000     -18.000000      0.520000      0.000000   \n",
              "25%        1.000000       7.000000      0.790000      0.000000   \n",
              "50%        3.000000      16.000000      0.880000      1.000000   \n",
              "75%        6.000000      42.000000      0.950000      1.000000   \n",
              "max    17355.000000  107201.000000      1.000000      1.000000   \n",
              "\n",
              "       num_comments_scaled  score_scaled  \n",
              "count         16352.000000  16696.000000  \n",
              "mean              1.381318      0.011469  \n",
              "std               1.182892      0.835368  \n",
              "min               0.000000     -7.206192  \n",
              "25%               0.693147     -0.335112  \n",
              "50%               1.386294     -0.208842  \n",
              "75%               1.945910     -0.006840  \n",
              "max               9.761694      8.318429  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b54b1b5a-6e9a-4a15-ab80-8ac2b01b3af9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_comments</th>\n",
              "      <th>score</th>\n",
              "      <th>upvote_ratio</th>\n",
              "      <th>2_way_label</th>\n",
              "      <th>num_comments_scaled</th>\n",
              "      <th>score_scaled</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>16352.000000</td>\n",
              "      <td>16696.000000</td>\n",
              "      <td>16352.000000</td>\n",
              "      <td>16696.000000</td>\n",
              "      <td>16352.000000</td>\n",
              "      <td>16696.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>14.679428</td>\n",
              "      <td>618.658840</td>\n",
              "      <td>0.860627</td>\n",
              "      <td>0.506049</td>\n",
              "      <td>1.381318</td>\n",
              "      <td>0.011469</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>158.367384</td>\n",
              "      <td>4407.505596</td>\n",
              "      <td>0.107915</td>\n",
              "      <td>0.499978</td>\n",
              "      <td>1.182892</td>\n",
              "      <td>0.835368</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>-18.000000</td>\n",
              "      <td>0.520000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-7.206192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>0.790000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.693147</td>\n",
              "      <td>-0.335112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>0.880000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.386294</td>\n",
              "      <td>-0.208842</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>6.000000</td>\n",
              "      <td>42.000000</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.945910</td>\n",
              "      <td>-0.006840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>17355.000000</td>\n",
              "      <td>107201.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>9.761694</td>\n",
              "      <td>8.318429</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b54b1b5a-6e9a-4a15-ab80-8ac2b01b3af9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b54b1b5a-6e9a-4a15-ab80-8ac2b01b3af9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b54b1b5a-6e9a-4a15-ab80-8ac2b01b3af9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-e87b3dd2-5e89-4a2f-949a-87d632d23c7c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e87b3dd2-5e89-4a2f-949a-87d632d23c7c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-e87b3dd2-5e89-4a2f-949a-87d632d23c7c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df_test\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"num_comments\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7792.325543201969,\n        \"min\": 0.0,\n        \"max\": 17355.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          14.67942759295499,\n          3.0,\n          16352.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 37247.16506946461,\n        \"min\": -18.0,\n        \"max\": 107201.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          618.6588404408242,\n          16.0,\n          16696.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"upvote_ratio\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5781.047030017327,\n        \"min\": 0.10791491418871677,\n        \"max\": 16352.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.8606268346379647,\n          0.88,\n          16352.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"2_way_label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5902.725089073998,\n        \"min\": 0.0,\n        \"max\": 16696.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.5060493531384763,\n          1.0,\n          0.49997837721033483\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"num_comments_scaled\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5780.480002758915,\n        \"min\": 0.0,\n        \"max\": 16352.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          1.3813176614147689,\n          1.3862943611198906,\n          16352.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score_scaled\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5902.857753138208,\n        \"min\": -7.206192375869276,\n        \"max\": 16696.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.011469452511206856,\n          -0.20884222335833214,\n          16696.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dropcol = ['num_comments','score']\n",
        "df_train = df_train.drop(columns=dropcol, errors='ignore')\n",
        "df_test = df_test.drop(columns=dropcol, errors='ignore')"
      ],
      "metadata": {
        "id": "UxJZ4E0C1t_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "l7mdaAjA4PTj",
        "outputId": "389b60b1-9978-4044-8b59-054fa4f8ae40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "upvote_ratio           2980\n",
              "2_way_label               0\n",
              "num_comments_scaled    2980\n",
              "score_scaled              0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>upvote_ratio</th>\n",
              "      <td>2980</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2_way_label</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>num_comments_scaled</th>\n",
              "      <td>2980</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>score_scaled</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['upvote_ratio'].fillna(df_train['upvote_ratio'].mean(), inplace=True)\n",
        "df_test['num_comments_scaled'].fillna(df_test['num_comments_scaled'].mean(), inplace=True)\n",
        "df_train['num_comments_scaled'].fillna(df_train['num_comments_scaled'].mean(), inplace=True)\n",
        "df_test['upvote_ratio'].fillna(df_test['upvote_ratio'].mean(), inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDeEGX424ThT",
        "outputId": "969eeb7c-7553-4ead-fe38-a8ac315286fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2693053216.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_train['upvote_ratio'].fillna(df_train['upvote_ratio'].mean(), inplace=True)\n",
            "/tmp/ipython-input-2693053216.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_test['num_comments_scaled'].fillna(df_test['num_comments_scaled'].mean(), inplace=True)\n",
            "/tmp/ipython-input-2693053216.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_train['num_comments_scaled'].fillna(df_train['num_comments_scaled'].mean(), inplace=True)\n",
            "/tmp/ipython-input-2693053216.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_test['upvote_ratio'].fillna(df_test['upvote_ratio'].mean(), inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "ZdsZwBQ45CIs",
        "outputId": "69bf69bc-a491-41c7-c765-402ed0ccbdbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "upvote_ratio           0\n",
              "2_way_label            0\n",
              "num_comments_scaled    0\n",
              "score_scaled           0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>upvote_ratio</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2_way_label</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>num_comments_scaled</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>score_scaled</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "x_img_train = np.load('/content/drive/MyDrive/ML-Project/clip_embeddings_multimodal/X_img_train.npy')\n",
        "x_img_test = np.load('/content/drive/MyDrive/ML-Project/clip_embeddings_multimodal/X_img_test.npy')\n",
        "x_txt_train = np.load('/content/drive/MyDrive/ML-Project/clip_embeddings_multimodal/X_txt_train.npy')\n",
        "x_txt_test = np.load('/content/drive/MyDrive/ML-Project/clip_embeddings_multimodal/X_txt_test.npy')"
      ],
      "metadata": {
        "id": "saWj6SJZ2a1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine embeddings along last axis\n",
        "x_train_embed = np.concatenate([x_img_train, x_txt_train], axis=1)\n",
        "x_test_embed  = np.concatenate([x_img_test, x_txt_test], axis=1)\n"
      ],
      "metadata": {
        "id": "wTKeW1jt3Xij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_features = ['num_comments_scaled', 'score_scaled', 'upvote_ratio']\n",
        "# Extract numeric features as numpy arrays\n",
        "x_train_num = df_train[num_features].to_numpy()\n",
        "x_test_num  = df_test[num_features].to_numpy()\n",
        "\n",
        "# Concatenate numeric + multimodal embeddings\n",
        "X_train_full = np.concatenate([x_train_num, x_train_embed], axis=1)\n",
        "X_test_full  = np.concatenate([x_test_num,  x_test_embed], axis=1)\n"
      ],
      "metadata": {
        "id": "ar769gfS3YkG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = df_train['2_way_label'].values\n",
        "y_test  = df_test['2_way_label'].values\n"
      ],
      "metadata": {
        "id": "T-se-yCF3hEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "early fusion\n"
      ],
      "metadata": {
        "id": "Fd51AAoCVACR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from lightgbm import LGBMClassifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from openpyxl import Workbook, load_workbook\n",
        "from openpyxl.styles import Alignment, Font\n",
        "from openpyxl.utils import get_column_letter\n",
        "\n",
        "\n",
        "# =========================\n",
        "# DEVICE SETUP\n",
        "# =========================\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\" Using device: {device}\")\n",
        "\n",
        "\n",
        "# =========================\n",
        "# MULTIMODAL TRAINING FUNCTION\n",
        "# =========================\n",
        "def train_and_save_models_to_excel(\n",
        "    X_train, y_train, X_test, y_test,\n",
        "    model_tag=\"Early Fusion (Tabular + Image + Text)\",\n",
        "    excel_path=\"/content/drive/MyDrive/results_local/multimodal_results.xlsx\",\n",
        "    scale_features=False\n",
        "):\n",
        "    \"\"\"\n",
        "    Train multiple classifiers on fused multimodal embeddings\n",
        "    and save their performance metrics to an Excel file.\n",
        "    \"\"\"\n",
        "\n",
        "    # Optionally scale features\n",
        "    if scale_features:\n",
        "        print(\" Scaling features using StandardScaler...\")\n",
        "        scaler = StandardScaler()\n",
        "        X_train = scaler.fit_transform(X_train)\n",
        "        X_test = scaler.transform(X_test)\n",
        "\n",
        "    # =========================\n",
        "    # DEFINE MODELS\n",
        "    # =========================\n",
        "    models = {\n",
        "        \"LogisticRegression\": LogisticRegression(max_iter=1000, multi_class='ovr'),\n",
        "        # \"RandomForest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "        # \"ExtraTrees\": ExtraTreesClassifier(n_estimators=100, random_state=42),\n",
        "        \"LightGBM\": LGBMClassifier(device=\"gpu\" if device == \"cuda\" else \"cpu\"),\n",
        "        \"XGBoost\": XGBClassifier(\n",
        "            tree_method=\"gpu_hist\" if device == \"cuda\" else \"auto\",\n",
        "            gpu_id=0 if device == \"cuda\" else None,\n",
        "            use_label_encoder=False,\n",
        "            eval_metric=\"logloss\"\n",
        "        ),\n",
        "        \"NaiveBayes\": GaussianNB()\n",
        "    }\n",
        "\n",
        "    # =========================\n",
        "    # PREPARE EXCEL FILE\n",
        "    # =========================\n",
        "    if os.path.exists(excel_path):\n",
        "        wb = load_workbook(excel_path)\n",
        "        ws = wb.active\n",
        "        next_row = ws.max_row + 2\n",
        "    else:\n",
        "        wb = Workbook()\n",
        "        ws = wb.active\n",
        "        ws.title = \"Model Results\"\n",
        "\n",
        "        # Title\n",
        "        ws.merge_cells('A1:E1')\n",
        "        ws['A1'] = model_tag\n",
        "        ws['A1'].font = Font(size=14, bold=True)\n",
        "        ws['A1'].alignment = Alignment(horizontal=\"center\")\n",
        "\n",
        "        headers = [\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"]\n",
        "        ws.append(headers)\n",
        "        next_row = ws.max_row + 1\n",
        "\n",
        "    # =========================\n",
        "    # TRAIN & EVALUATE\n",
        "    # =========================\n",
        "    for name, model in models.items():\n",
        "        print(f\"\\n Training {name}...\")\n",
        "        try:\n",
        "            model.fit(X_train, y_train)\n",
        "            y_pred = model.predict(X_test)\n",
        "\n",
        "            acc = accuracy_score(y_test, y_pred)\n",
        "            prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "            rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "            f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "\n",
        "            print(f\" {name}: Acc={acc:.4f}, Prec={prec:.4f}, Rec={rec:.4f}, F1={f1:.4f}\")\n",
        "\n",
        "            ws.append([name, acc, prec, rec, f1])\n",
        "        except Exception as e:\n",
        "            print(f\" Error training {name}: {e}\")\n",
        "            ws.append([name, \"ERROR\", \"ERROR\", \"ERROR\", \"ERROR\"])\n",
        "\n",
        "    # =========================\n",
        "    # FORMAT & SAVE\n",
        "    # =========================\n",
        "    for col in range(1, 6):\n",
        "        ws.column_dimensions[get_column_letter(col)].width = 15\n",
        "\n",
        "    ws.append([])  # Add spacing between result blocks\n",
        "    wb.save(excel_path)\n",
        "    print(f\"\\n Results saved to: {excel_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fw49SajT4L-J",
        "outputId": "3b0c945c-94eb-48ab-9b47-68566dd1d455"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_and_save_models_to_excel(\n",
        "    X_train_full, y_train,\n",
        "    X_test_full, y_test,\n",
        "    model_tag=\"Early Fusion: Tabular + Image + Text\",\n",
        "    scale_features=True  # good practice for linear models\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3l5gnSm6o_5",
        "outputId": "06531615-4efd-49f5-926c-0eee6a953ad8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Scaling features using StandardScaler...\n",
            "\n",
            " Training LogisticRegression...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " LogisticRegression: Acc=0.9102, Prec=0.9102, Rec=0.9102, F1=0.9101\n",
            "\n",
            " Training LightGBM...\n",
            "[LightGBM] [Info] Number of positive: 81461, number of negative: 78725\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 261682\n",
            "[LightGBM] [Info] Number of data points in the train set: 160186, number of used features: 1027\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 1027 dense feature groups (157.04 MB) transferred to GPU in 0.313812 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.508540 -> initscore=0.034164\n",
            "[LightGBM] [Info] Start training from score 0.034164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " LightGBM: Acc=0.9051, Prec=0.9055, Rec=0.9051, F1=0.9051\n",
            "\n",
            " Training XGBoost...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [05:01:54] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [05:01:54] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [05:01:54] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/core.py:2676: UserWarning: [05:02:01] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [05:02:01] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
            "Potential solutions:\n",
            "- Use a data structure that matches the device ordinal in the booster.\n",
            "- Set the device for booster before call to inplace_predict.\n",
            "\n",
            "This warning will only be shown once.\n",
            "\n",
            "  return func(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " XGBoost: Acc=0.9214, Prec=0.9216, Rec=0.9214, F1=0.9214\n",
            "\n",
            " Training NaiveBayes...\n",
            " NaiveBayes: Acc=0.7978, Prec=0.7978, Rec=0.7978, F1=0.7978\n",
            "\n",
            " Results saved to: /content/drive/MyDrive/results_local/multimodal_results.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from xgboost import XGBClassifier, DMatrix, cv\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\" Using device: {device}\")\n",
        "\n",
        "def train_optimized_xgboost(\n",
        "    X_train, y_train, X_test, y_test,\n",
        "    excel_path=\"/content/drive/MyDrive/results_local/xgboost_optimized_results.xlsx\",\n",
        "    scale_features=False\n",
        "):\n",
        "    if scale_features:\n",
        "        print(\" Scaling features using StandardScaler...\")\n",
        "        scaler = StandardScaler()\n",
        "        X_train = scaler.fit_transform(X_train)\n",
        "        X_test = scaler.transform(X_test)\n",
        "\n",
        "    # ======================================\n",
        "    # XGBOOST PARAMETERS (Tuned for GPU)\n",
        "    # ======================================\n",
        "    params = {\n",
        "        \"tree_method\": \"gpu_hist\",  # full GPU acceleration\n",
        "        \"gpu_id\": 0,\n",
        "        \"objective\": \"multi:softmax\" if len(np.unique(y_train)) > 2 else \"binary:logistic\",\n",
        "        \"num_class\": len(np.unique(y_train)) if len(np.unique(y_train)) > 2 else None,\n",
        "        \"eval_metric\": \"mlogloss\" if len(np.unique(y_train)) > 2 else \"logloss\",\n",
        "        \"learning_rate\": 0.03,\n",
        "        \"max_depth\": 8,\n",
        "        \"min_child_weight\": 3,\n",
        "        \"subsample\": 0.8,\n",
        "        \"colsample_bytree\": 0.8,\n",
        "        \"reg_alpha\": 0.1,  # L1 regularization\n",
        "        \"reg_lambda\": 1.0, # L2 regularization\n",
        "        \"n_estimators\": 2000,\n",
        "        \"early_stopping_rounds\": 50,\n",
        "        \"verbosity\": 1,\n",
        "        \"random_state\": 42\n",
        "    }\n",
        "\n",
        "    # ======================================\n",
        "    # TRAIN MODEL WITH EARLY STOPPING\n",
        "    # ======================================\n",
        "    print(\" Training XGBoost with GPU acceleration...\")\n",
        "\n",
        "    model = XGBClassifier(**params)\n",
        "    model.fit(\n",
        "        X_train, y_train,\n",
        "        eval_set=[(X_test, y_test)],\n",
        "        verbose=100\n",
        "    )\n",
        "\n",
        "    # ======================================\n",
        "    # PREDICT & EVALUATE\n",
        "    # ======================================\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "    rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "\n",
        "    print(f\"\\n Final XGBoost Results:\")\n",
        "    print(f\"Accuracy: {acc:.4f}\")\n",
        "    print(f\"Precision: {prec:.4f}\")\n",
        "    print(f\"Recall: {rec:.4f}\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "\n",
        "    # ======================================\n",
        "    # SAVE MODEL\n",
        "    # ======================================\n",
        "    model.save_model(\"/content/drive/MyDrive/results_local/xgboost_optimized_model.json\")\n",
        "    print(\" Model saved to Google Drive.\")\n",
        "\n",
        "    # ======================================\n",
        "    # SAVE RESULTS TO EXCEL\n",
        "    # ======================================\n",
        "    from openpyxl import Workbook, load_workbook\n",
        "    from openpyxl.styles import Alignment, Font\n",
        "    from openpyxl.utils import get_column_letter\n",
        "\n",
        "    if os.path.exists(excel_path):\n",
        "        wb = load_workbook(excel_path)\n",
        "        ws = wb.active\n",
        "    else:\n",
        "        wb = Workbook()\n",
        "        ws = wb.active\n",
        "        ws.title = \"XGBoost Results\"\n",
        "        ws.append([\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"])\n",
        "\n",
        "    ws.append([\"XGBoost Optimized\", acc, prec, rec, f1])\n",
        "\n",
        "    for col in range(1, 6):\n",
        "        ws.column_dimensions[get_column_letter(col)].width = 15\n",
        "\n",
        "    wb.save(excel_path)\n",
        "    print(f\" Results saved to: {excel_path}\")\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xHaz3LFTlDZ",
        "outputId": "6df59810-8b87-4c07-e9f7-e0f23aa580f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = train_optimized_xgboost(X_train_full, y_train,\n",
        "    X_test_full, y_test,)\n",
        "\n",
        "print(\"\\n Training complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TignIjPjZCkg",
        "outputId": "a3dc2205-a9f3-469e-8e55-1b5f7c0a124f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Training XGBoost with GPU acceleration...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [15:37:01] WARNING: /workspace/src/common/error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\n",
            "  self.starting_round = model.num_boosted_rounds()\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/callback.py:386: UserWarning: [15:37:01] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  self.starting_round = model.num_boosted_rounds()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\tvalidation_0-logloss:0.67702\n",
            "[100]\tvalidation_0-logloss:0.27850\n",
            "[200]\tvalidation_0-logloss:0.22504\n",
            "[300]\tvalidation_0-logloss:0.20306\n",
            "[400]\tvalidation_0-logloss:0.19085\n",
            "[500]\tvalidation_0-logloss:0.18278\n",
            "[600]\tvalidation_0-logloss:0.17701\n",
            "[700]\tvalidation_0-logloss:0.17225\n",
            "[800]\tvalidation_0-logloss:0.16881\n",
            "[900]\tvalidation_0-logloss:0.16592\n",
            "[1000]\tvalidation_0-logloss:0.16402\n",
            "[1100]\tvalidation_0-logloss:0.16241\n",
            "[1200]\tvalidation_0-logloss:0.16122\n",
            "[1300]\tvalidation_0-logloss:0.16020\n",
            "[1400]\tvalidation_0-logloss:0.15949\n",
            "[1500]\tvalidation_0-logloss:0.15897\n",
            "[1600]\tvalidation_0-logloss:0.15857\n",
            "[1666]\tvalidation_0-logloss:0.15858\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/core.py:2676: UserWarning: [15:40:14] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/core.py:729: UserWarning: [15:40:14] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
            "Potential solutions:\n",
            "- Use a data structure that matches the device ordinal in the booster.\n",
            "- Set the device for booster before call to inplace_predict.\n",
            "\n",
            "This warning will only be shown once.\n",
            "\n",
            "  return func(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Final XGBoost Results:\n",
            "Accuracy: 0.9362\n",
            "Precision: 0.9364\n",
            "Recall: 0.9362\n",
            "F1 Score: 0.9361\n",
            " Model saved to Google Drive.\n",
            " Results saved to: /content/drive/MyDrive/results_local/xgboost_optimized_results.xlsx\n",
            "\n",
            " Training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import optuna\n",
        "import xgboost as xgb\n",
        "from google.colab import drive\n",
        "from openpyxl import Workbook, load_workbook\n",
        "from openpyxl.utils import get_column_letter\n",
        "\n",
        "# =====================================================\n",
        "# SETUP\n",
        "# =====================================================\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\" Using device: {device}\")\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)\n",
        "os.makedirs(\"/content/drive/MyDrive/results_local\", exist_ok=True)\n",
        "\n",
        "\n",
        "# =====================================================\n",
        "# TRAIN FUNCTION\n",
        "# =====================================================\n",
        "def train_optimized_xgboost(\n",
        "    X_train_full, y_train_full, X_test_full, y_test,\n",
        "    excel_path=\"/content/drive/MyDrive/results_local/xgboost_optimized_results.xlsx\",\n",
        "    scale_features=False,\n",
        "    n_trials=10\n",
        "):\n",
        "    # =====================================================\n",
        "    #  Sanity check\n",
        "    # =====================================================\n",
        "    print(\"Checking data consistency...\")\n",
        "    print(f\"X_train_full shape: {X_train_full.shape}\")\n",
        "    print(f\"y_train_full shape: {y_train_full.shape}\")\n",
        "    print(f\"X_test_full shape: {X_test_full.shape}\")\n",
        "    print(f\"y_test shape: {y_test.shape}\")\n",
        "\n",
        "    assert X_train_full.shape[0] == len(y_train_full), \" Mismatch between X_train_full and y_train_full length!\"\n",
        "    assert X_test_full.shape[0] == len(y_test), \" Mismatch between X_test_full and y_test length!\"\n",
        "\n",
        "    # =====================================================\n",
        "    #  Feature scaling\n",
        "    # =====================================================\n",
        "    if scale_features:\n",
        "        print(\" Scaling features using StandardScaler...\")\n",
        "        scaler = StandardScaler()\n",
        "        X_train = scaler.fit_transform(X_train_full)\n",
        "        X_test = scaler.transform(X_test_full)\n",
        "    else:\n",
        "        X_train, X_test = X_train_full, X_test_full\n",
        "\n",
        "    y_train = np.array(y_train_full).ravel()\n",
        "    y_test = np.array(y_test).ravel()\n",
        "\n",
        "    num_classes = len(np.unique(y_train))\n",
        "    objective_name = \"multi:softmax\" if num_classes > 2 else \"binary:logistic\"\n",
        "    eval_metric = \"mlogloss\" if num_classes > 2 else \"logloss\"\n",
        "\n",
        "    # =====================================================\n",
        "    #  Define Optuna objective\n",
        "    # =====================================================\n",
        "    def objective(trial):\n",
        "        params = {\n",
        "            \"objective\": objective_name,\n",
        "            \"eval_metric\": eval_metric,\n",
        "            \"tree_method\": \"gpu_hist\",\n",
        "            \"gpu_id\": 0,\n",
        "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
        "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
        "            \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 8),\n",
        "            \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
        "            \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
        "            \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0.0, 1.0),\n",
        "            \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0.0, 5.0),\n",
        "            \"n_estimators\": 600,\n",
        "            \"verbosity\": 0,\n",
        "            \"random_state\": 42,\n",
        "        }\n",
        "\n",
        "        model = xgb.XGBClassifier(**params)\n",
        "        kf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "        f1_scores = []\n",
        "\n",
        "        for train_idx, val_idx in kf.split(X_train, y_train):\n",
        "            X_t, X_v = X_train[train_idx], X_train[val_idx]\n",
        "            y_t, y_v = y_train[train_idx], y_train[val_idx]\n",
        "            model.fit(X_t, y_t, eval_set=[(X_v, y_v)], verbose=False)\n",
        "            preds = model.predict(X_v)\n",
        "            score = f1_score(y_v, preds, average=\"weighted\", zero_division=0)\n",
        "            f1_scores.append(score)\n",
        "\n",
        "        return np.mean(f1_scores)\n",
        "\n",
        "    # =====================================================\n",
        "    #  Run Optuna optimization\n",
        "    # =====================================================\n",
        "    print(f\" Running Optuna optimization ({n_trials} trials)...\")\n",
        "    study = optuna.create_study(direction=\"maximize\")\n",
        "    study.optimize(objective, n_trials=n_trials)\n",
        "\n",
        "    best_params = study.best_params\n",
        "    print(\" Best Parameters:\")\n",
        "    for k, v in best_params.items():\n",
        "        print(f\"   {k}: {v}\")\n",
        "\n",
        "    # =====================================================\n",
        "    #  Train final model\n",
        "    # =====================================================\n",
        "    best_params.update({\n",
        "        \"objective\": objective_name,\n",
        "        \"eval_metric\": eval_metric,\n",
        "        \"tree_method\": \"gpu_hist\",\n",
        "        \"gpu_id\": 0,\n",
        "        \"n_estimators\": 1000,\n",
        "        \"verbosity\": 1,\n",
        "        \"random_state\": 42,\n",
        "    })\n",
        "\n",
        "    print(\"\\n Training final model with best parameters...\")\n",
        "    model = xgb.XGBClassifier(**best_params)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # =====================================================\n",
        "    #  Evaluate\n",
        "    # =====================================================\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "    rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "\n",
        "    print(f\"\\n Final XGBoost Results:\")\n",
        "    print(f\"Accuracy:  {acc:.4f}\")\n",
        "    print(f\"Precision: {prec:.4f}\")\n",
        "    print(f\"Recall:    {rec:.4f}\")\n",
        "    print(f\"F1 Score:  {f1:.4f}\")\n",
        "\n",
        "    # =====================================================\n",
        "    #  Save model\n",
        "    # =====================================================\n",
        "    model.save_model(\"/content/drive/MyDrive/results_local/xgboost_optimized_model.json\")\n",
        "    print(\" Model saved to Google Drive.\")\n",
        "\n",
        "    # =====================================================\n",
        "    #  Save results to Excel\n",
        "    # =====================================================\n",
        "    if os.path.exists(excel_path):\n",
        "        wb = load_workbook(excel_path)\n",
        "        ws = wb.active\n",
        "    else:\n",
        "        wb = Workbook()\n",
        "        ws = wb.active\n",
        "        ws.title = \"XGBoost Results\"\n",
        "        ws.append([\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"])\n",
        "\n",
        "    ws.append([\"XGBoost Optimized\", acc, prec, rec, f1])\n",
        "\n",
        "    for col in range(1, 6):\n",
        "        ws.column_dimensions[get_column_letter(col)].width = 15\n",
        "\n",
        "    wb.save(excel_path)\n",
        "    print(f\" Results saved to: {excel_path}\")\n",
        "\n",
        "    print(\"\\n Training complete!\")\n",
        "    return model\n",
        "\n",
        "\n",
        "# =====================================================\n",
        "#  Example Usage\n",
        "# =====================================================\n",
        "# Make sure your arrays are numpy arrays (not lists or DataFrames)\n",
        "X_train_full = np.array(X_train_full)\n",
        "X_test_full = np.array(X_test_full)\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "model = train_optimized_xgboost(\n",
        "    X_train_full, y_train,\n",
        "    X_test_full, y_test,\n",
        "    scale_features=True,\n",
        "    n_trials=10\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJfB6NKscXL_",
        "outputId": "671058b0-c7b3-474c-e326-c70dd2b4d3ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Using device: cuda\n",
            "Mounted at /content/drive\n",
            "Checking data consistency...\n",
            "X_train_full shape: (160186, 1027)\n",
            "y_train_full shape: (160186,)\n",
            "X_test_full shape: (16696, 1027)\n",
            "y_test shape: (16696,)\n",
            " Scaling features using StandardScaler...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-10-21 16:08:58,929] A new study created in memory with name: no-name-0ddc5d17-233e-406b-8a69-4c3bd911551c\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Running Optuna optimization (10 trials)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-10-21 16:11:23,363] Trial 0 finished with value: 0.9236620969563898 and parameters: {'learning_rate': 0.2412960131859455, 'max_depth': 4, 'min_child_weight': 5, 'subsample': 0.9702533105063688, 'colsample_bytree': 0.9469320409846743, 'reg_alpha': 0.6464420675442873, 'reg_lambda': 4.194129205626453}. Best is trial 0 with value: 0.9236620969563898.\n",
            "[I 2025-10-21 16:13:36,370] Trial 1 finished with value: 0.9160148350824349 and parameters: {'learning_rate': 0.11189704236372373, 'max_depth': 3, 'min_child_weight': 1, 'subsample': 0.713125171657147, 'colsample_bytree': 0.9149074042177482, 'reg_alpha': 0.9429973143750237, 'reg_lambda': 4.53392152078178}. Best is trial 0 with value: 0.9236620969563898.\n",
            "[I 2025-10-21 16:17:18,424] Trial 2 finished with value: 0.928355481855882 and parameters: {'learning_rate': 0.14860595117748682, 'max_depth': 7, 'min_child_weight': 3, 'subsample': 0.7176599664538083, 'colsample_bytree': 0.8886444328652388, 'reg_alpha': 0.6540797493167583, 'reg_lambda': 1.7238210282782818}. Best is trial 2 with value: 0.928355481855882.\n",
            "[I 2025-10-21 16:21:07,919] Trial 3 finished with value: 0.9289184482065448 and parameters: {'learning_rate': 0.19323814364857392, 'max_depth': 7, 'min_child_weight': 2, 'subsample': 0.7573096086364286, 'colsample_bytree': 0.9716267589056101, 'reg_alpha': 0.4447217227456406, 'reg_lambda': 3.015207566377878}. Best is trial 3 with value: 0.9289184482065448.\n",
            "[I 2025-10-21 16:27:03,720] Trial 4 finished with value: 0.9275155208385278 and parameters: {'learning_rate': 0.09676332735764664, 'max_depth': 9, 'min_child_weight': 2, 'subsample': 0.6641148359814967, 'colsample_bytree': 0.8786747321458199, 'reg_alpha': 0.9567908572896203, 'reg_lambda': 1.3115089235991384}. Best is trial 3 with value: 0.9289184482065448.\n",
            "[I 2025-10-21 16:31:23,795] Trial 5 finished with value: 0.9279314442928767 and parameters: {'learning_rate': 0.25228897899725783, 'max_depth': 8, 'min_child_weight': 1, 'subsample': 0.7024773649180476, 'colsample_bytree': 0.6629236314694643, 'reg_alpha': 0.8960686842945355, 'reg_lambda': 4.763374915516097}. Best is trial 3 with value: 0.9289184482065448.\n",
            "[I 2025-10-21 16:34:54,066] Trial 6 finished with value: 0.9257349054535147 and parameters: {'learning_rate': 0.27903785684226795, 'max_depth': 7, 'min_child_weight': 3, 'subsample': 0.618464832797049, 'colsample_bytree': 0.8324346233387816, 'reg_alpha': 0.34864036183065406, 'reg_lambda': 4.838062964129432}. Best is trial 3 with value: 0.9289184482065448.\n",
            "[I 2025-10-21 16:39:37,021] Trial 7 finished with value: 0.926493827869287 and parameters: {'learning_rate': 0.053080721386318794, 'max_depth': 8, 'min_child_weight': 7, 'subsample': 0.6707956910368004, 'colsample_bytree': 0.946243111746448, 'reg_alpha': 0.944025575042817, 'reg_lambda': 2.950884474879389}. Best is trial 3 with value: 0.9289184482065448.\n",
            "[I 2025-10-21 16:42:02,614] Trial 8 finished with value: 0.9079820515105551 and parameters: {'learning_rate': 0.034381760703073826, 'max_depth': 4, 'min_child_weight': 3, 'subsample': 0.7016768369544973, 'colsample_bytree': 0.8796014877026008, 'reg_alpha': 0.8007689873625518, 'reg_lambda': 3.3350272562947247}. Best is trial 3 with value: 0.9289184482065448.\n",
            "[I 2025-10-21 16:44:20,977] Trial 9 finished with value: 0.923161844292689 and parameters: {'learning_rate': 0.19346984064084632, 'max_depth': 4, 'min_child_weight': 2, 'subsample': 0.8704880611968724, 'colsample_bytree': 0.7449633958276617, 'reg_alpha': 0.3081348053592451, 'reg_lambda': 3.956191887802258}. Best is trial 3 with value: 0.9289184482065448.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Best Parameters:\n",
            "   learning_rate: 0.19323814364857392\n",
            "   max_depth: 7\n",
            "   min_child_weight: 2\n",
            "   subsample: 0.7573096086364286\n",
            "   colsample_bytree: 0.9716267589056101\n",
            "   reg_alpha: 0.4447217227456406\n",
            "   reg_lambda: 3.015207566377878\n",
            "\n",
            " Training final model with best parameters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [16:44:56] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/core.py:2676: UserWarning: [16:46:24] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Final XGBoost Results:\n",
            "Accuracy:  0.9362\n",
            "Precision: 0.9364\n",
            "Recall:    0.9362\n",
            "F1 Score:  0.9362\n",
            " Model saved to Google Drive.\n",
            " Results saved to: /content/drive/MyDrive/results_local/xgboost_optimized_results.xlsx\n",
            "\n",
            " Training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "xgb.plot_importance(model, max_num_features=20)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "KaGmO3vKrOKd",
        "outputId": "8fd8585f-80cc-493e-e65c-65e487232477"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "# cm = confusion_matrix(y_test, model.predict(X_test_full))\n",
        "y_pred = model.predict(X_test_full)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "ConfusionMatrixDisplay(cm).plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "id": "2mUVXvDDrr-D",
        "outputId": "694aea57-b814-4c99-c5eb-648c03a64d87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[5006 3241]\n",
            " [5268 3181]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.classes_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8MMoNaHsw0k",
        "outputId": "c13835cf-79bf-4974-dd26-68b244f707f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"X_train_full shape:\", X_train_full.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"X_test_full shape:\", X_test_full.shape)\n",
        "print(\"y_test shape:\", y_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8ydFAy2f30k",
        "outputId": "6266747b-07fa-4a3e-e405-c03f87a7989b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train_full shape: (160186, 1027)\n",
            "y_train shape: (160186,)\n",
            "X_test_full shape: (16696, 1027)\n",
            "y_test shape: (16696,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "late fusion\n",
        "\"\"\"\n",
        "  Late fusion: trains multiple models per modality, fuses predictions,\n",
        "  and records all performance metrics in Excel.\n",
        "  \"\"\""
      ],
      "metadata": {
        "id": "BMHbX9XEBHXZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from lightgbm import LGBMClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from openpyxl import Workbook, load_workbook\n",
        "from openpyxl.styles import Alignment, Font\n",
        "from openpyxl.utils import get_column_letter\n",
        "\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\" Using device: {device}\")\n",
        "\n",
        "\n",
        "def late_fusion_multi_model(\n",
        "    x_img_train, x_img_test,\n",
        "    x_txt_train, x_txt_test,\n",
        "    x_tab_train, x_tab_test,\n",
        "    y_train, y_test,\n",
        "    excel_path=\"/content/drive/MyDrive/results_local/multimodal_results.xlsx\",\n",
        "    fusion_weights=(0.4, 0.4, 0.2)\n",
        "):\n",
        "    \"\"\"\n",
        "    Late fusion: trains multiple models per modality, fuses predictions,\n",
        "    and records all performance metrics in Excel.\n",
        "    \"\"\"\n",
        "\n",
        "    # =======================\n",
        "    # DEFINE MODELS\n",
        "    # =======================\n",
        "    base_models = {\n",
        "        \"XGBoost\": XGBClassifier(\n",
        "            tree_method=\"gpu_hist\" if device == \"cuda\" else \"hist\",\n",
        "            gpu_id=0 if device == \"cuda\" else None,\n",
        "            use_label_encoder=False,\n",
        "            eval_metric=\"logloss\",\n",
        "            n_estimators=800,\n",
        "            learning_rate=0.05\n",
        "        ),\n",
        "        \"LightGBM\": LGBMClassifier(\n",
        "            n_estimators=1000, learning_rate=0.05,\n",
        "            device=\"gpu\" if device == \"cuda\" else \"cpu\"\n",
        "        ),\n",
        "        \"LogisticRegression\": LogisticRegression(max_iter=1000, solver=\"saga\", n_jobs=-1),\n",
        "        # \"RandomForest\": RandomForestClassifier(n_estimators=100, max_depth=15, n_jobs=-1, random_state=42),\n",
        "        # \"ExtraTrees\": ExtraTreesClassifier(n_estimators=100, max_depth=15, n_jobs=-1, random_state=42),\n",
        "        \"NaiveBayes\": GaussianNB()\n",
        "    }\n",
        "\n",
        "    # Prepare Excel\n",
        "    if os.path.exists(excel_path):\n",
        "        wb = load_workbook(excel_path)\n",
        "        ws = wb.active\n",
        "    else:\n",
        "        wb = Workbook()\n",
        "        ws = wb.active\n",
        "        ws.title = \"Late Fusion Results\"\n",
        "        ws.append([\"Fusion Setup\", \"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"])\n",
        "\n",
        "    w_img, w_txt, w_tab = fusion_weights\n",
        "\n",
        "    # =======================\n",
        "    # TRAIN MODELS PER MODALITY\n",
        "    # =======================\n",
        "    results = []\n",
        "\n",
        "    for img_name, img_model in base_models.items():\n",
        "        for txt_name, txt_model in base_models.items():\n",
        "            for tab_name, tab_model in base_models.items():\n",
        "                setup_name = f\"Img:{img_name} | Txt:{txt_name} | Tab:{tab_name}\"\n",
        "\n",
        "                try:\n",
        "                    print(f\"\\n Training setup: {setup_name}\")\n",
        "\n",
        "                    # ---- Image ----\n",
        "                    img_model.fit(x_img_train, y_train)\n",
        "                    img_pred = img_model.predict_proba(x_img_test)[:, 1]\n",
        "\n",
        "                    # ---- Text ----\n",
        "                    txt_model.fit(x_txt_train, y_train)\n",
        "                    txt_pred = txt_model.predict_proba(x_txt_test)[:, 1]\n",
        "\n",
        "                    # ---- Tabular ----\n",
        "                    scaler = StandardScaler()\n",
        "                    x_tab_train_scaled = scaler.fit_transform(x_tab_train)\n",
        "                    x_tab_test_scaled = scaler.transform(x_tab_test)\n",
        "                    tab_model.fit(x_tab_train_scaled, y_train)\n",
        "                    tab_pred = tab_model.predict_proba(x_tab_test_scaled)[:, 1]\n",
        "\n",
        "                    # ---- Fusion ----\n",
        "                    fused_pred = (\n",
        "                        w_img * img_pred +\n",
        "                        w_txt * txt_pred +\n",
        "                        w_tab * tab_pred\n",
        "                    )\n",
        "                    fused_pred_label = (fused_pred >= 0.5).astype(int)\n",
        "\n",
        "                    acc = accuracy_score(y_test, fused_pred_label)\n",
        "                    prec = precision_score(y_test, fused_pred_label, average='weighted', zero_division=0)\n",
        "                    rec = recall_score(y_test, fused_pred_label, average='weighted', zero_division=0)\n",
        "                    f1 = f1_score(y_test, fused_pred_label, average='weighted', zero_division=0)\n",
        "\n",
        "                    results.append((setup_name, acc, prec, rec, f1))\n",
        "                    ws.append([setup_name, acc, prec, rec, f1])\n",
        "                    print(f\" {setup_name}  Acc={acc:.4f}, F1={f1:.4f}\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\" Error in {setup_name}: {e}\")\n",
        "                    ws.append([setup_name, \"ERROR\", \"ERROR\", \"ERROR\", \"ERROR\"])\n",
        "\n",
        "                wb.save(excel_path)\n",
        "\n",
        "    # =======================\n",
        "    # FIND BEST SETUP\n",
        "    # =======================\n",
        "    results_df = pd.DataFrame(results, columns=[\"Setup\", \"Accuracy\", \"Precision\", \"Recall\", \"F1\"])\n",
        "    best_row = results_df.loc[results_df[\"F1\"].idxmax()]\n",
        "    print(\"\\n Best Late Fusion Configuration:\")\n",
        "    print(best_row)\n",
        "\n",
        "    ws.append([])\n",
        "    ws.append([\"BEST MODEL\", best_row[\"Setup\"], best_row[\"Accuracy\"], best_row[\"Precision\"], best_row[\"Recall\"], best_row[\"F1\"]])\n",
        "    wb.save(excel_path)\n",
        "    print(f\"\\n Results saved and best configuration recorded to: {excel_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjTWNE-kBGrc",
        "outputId": "3954c4e5-26e2-4541-93d3-6dd8fc0ce546"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "late_fusion_multi_model(\n",
        "    x_img_train, x_img_test,\n",
        "    x_txt_train, x_txt_test,\n",
        "    df_train[['num_comments_scaled','score_scaled','upvote_ratio']],\n",
        "    df_test[['num_comments_scaled','score_scaled','upvote_ratio']],\n",
        "    y_train, y_test,\n",
        "    fusion_weights=(0.4, 0.4, 0.2)\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxGv0TqwBTav",
        "outputId": "aed09419-d3a3-45ba-e91c-63bbbf15666c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Training setup: Img:XGBoost | Txt:XGBoost | Tab:XGBoost\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [05:09:15] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [05:09:15] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/core.py:2676: UserWarning: [05:09:38] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [05:09:57] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [05:09:57] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/core.py:2676: UserWarning: [05:10:20] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [05:10:20] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [05:10:20] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/core.py:2676: UserWarning: [05:10:21] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Img:XGBoost | Txt:XGBoost | Tab:XGBoost  Acc=0.9121, F1=0.9120\n",
            "\n",
            " Training setup: Img:XGBoost | Txt:XGBoost | Tab:LightGBM\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [05:10:39] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [05:10:39] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/core.py:2676: UserWarning: [05:11:01] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [05:11:19] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [05:11:19] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/core.py:2676: UserWarning: [05:11:42] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 81461, number of negative: 78725\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 562\n",
            "[LightGBM] [Info] Number of data points in the train set: 160186, number of used features: 3\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 3 dense feature groups (0.61 MB) transferred to GPU in 0.001466 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.508540 -> initscore=0.034164\n",
            "[LightGBM] [Info] Start training from score 0.034164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Img:XGBoost | Txt:XGBoost | Tab:LightGBM  Acc=0.9114, F1=0.9113\n",
            "\n",
            " Training setup: Img:XGBoost | Txt:XGBoost | Tab:LogisticRegression\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [05:12:11] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [05:12:11] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/core.py:2676: UserWarning: [05:12:34] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [05:12:51] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [05:12:51] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/core.py:2676: UserWarning: [05:13:15] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Img:XGBoost | Txt:XGBoost | Tab:LogisticRegression  Acc=0.9037, F1=0.9036\n",
            "\n",
            " Training setup: Img:XGBoost | Txt:XGBoost | Tab:NaiveBayes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [05:13:33] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [05:13:33] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/core.py:2676: UserWarning: [05:13:56] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [05:14:13] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [05:14:13] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/core.py:2676: UserWarning: [05:14:37] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Img:XGBoost | Txt:XGBoost | Tab:NaiveBayes  Acc=0.8990, F1=0.8988\n",
            "\n",
            " Training setup: Img:XGBoost | Txt:LightGBM | Tab:XGBoost\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [05:14:55] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [05:14:55] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/core.py:2676: UserWarning: [05:15:18] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 81461, number of negative: 78725\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 130560\n",
            "[LightGBM] [Info] Number of data points in the train set: 160186, number of used features: 512\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 512 dense feature groups (78.22 MB) transferred to GPU in 0.166889 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.508540 -> initscore=0.034164\n",
            "[LightGBM] [Info] Start training from score 0.034164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [05:17:38] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [05:17:38] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/core.py:2676: UserWarning: [05:17:40] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Img:XGBoost | Txt:LightGBM | Tab:XGBoost  Acc=0.9124, F1=0.9123\n",
            "\n",
            " Training setup: Img:XGBoost | Txt:LightGBM | Tab:LightGBM\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [05:17:57] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [05:17:57] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/core.py:2676: UserWarning: [05:18:20] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 81461, number of negative: 78725\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 130560\n",
            "[LightGBM] [Info] Number of data points in the train set: 160186, number of used features: 512\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 512 dense feature groups (78.22 MB) transferred to GPU in 0.175070 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.508540 -> initscore=0.034164\n",
            "[LightGBM] [Info] Start training from score 0.034164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 81461, number of negative: 78725\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 562\n",
            "[LightGBM] [Info] Number of data points in the train set: 160186, number of used features: 3\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 3 dense feature groups (0.61 MB) transferred to GPU in 0.001917 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.508540 -> initscore=0.034164\n",
            "[LightGBM] [Info] Start training from score 0.034164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Img:XGBoost | Txt:LightGBM | Tab:LightGBM  Acc=0.9118, F1=0.9117\n",
            "\n",
            " Training setup: Img:XGBoost | Txt:LightGBM | Tab:LogisticRegression\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [05:21:08] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [05:21:08] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/core.py:2676: UserWarning: [05:21:31] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 81461, number of negative: 78725\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 130560\n",
            "[LightGBM] [Info] Number of data points in the train set: 160186, number of used features: 512\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 512 dense feature groups (78.22 MB) transferred to GPU in 0.152636 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.508540 -> initscore=0.034164\n",
            "[LightGBM] [Info] Start training from score 0.034164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Img:XGBoost | Txt:LightGBM | Tab:LogisticRegression  Acc=0.9030, F1=0.9029\n",
            "\n",
            " Training setup: Img:XGBoost | Txt:LightGBM | Tab:NaiveBayes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [05:24:08] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [05:24:08] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/core.py:2676: UserWarning: [05:24:30] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 81461, number of negative: 78725\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 130560\n",
            "[LightGBM] [Info] Number of data points in the train set: 160186, number of used features: 512\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 512 dense feature groups (78.22 MB) transferred to GPU in 0.316901 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.508540 -> initscore=0.034164\n",
            "[LightGBM] [Info] Start training from score 0.034164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Img:XGBoost | Txt:LightGBM | Tab:NaiveBayes  Acc=0.8982, F1=0.8981\n",
            "\n",
            " Training setup: Img:XGBoost | Txt:LogisticRegression | Tab:XGBoost\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [05:27:09] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [05:27:09] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/core.py:2676: UserWarning: [05:27:31] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [05:28:01] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [05:28:01] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/core.py:2676: UserWarning: [05:28:02] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Img:XGBoost | Txt:LogisticRegression | Tab:XGBoost  Acc=0.9081, F1=0.9080\n",
            "\n",
            " Training setup: Img:XGBoost | Txt:LogisticRegression | Tab:LightGBM\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [05:28:19] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [05:28:19] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/core.py:2676: UserWarning: [05:28:42] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 81461, number of negative: 78725\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 562\n",
            "[LightGBM] [Info] Number of data points in the train set: 160186, number of used features: 3\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 3 dense feature groups (0.61 MB) transferred to GPU in 0.001535 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.508540 -> initscore=0.034164\n",
            "[LightGBM] [Info] Start training from score 0.034164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Img:XGBoost | Txt:LogisticRegression | Tab:LightGBM  Acc=0.9078, F1=0.9078\n",
            "\n",
            " Training setup: Img:XGBoost | Txt:LogisticRegression | Tab:LogisticRegression\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [05:29:39] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [05:29:39] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/core.py:2676: UserWarning: [05:30:02] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Img:XGBoost | Txt:LogisticRegression | Tab:LogisticRegression  Acc=0.8975, F1=0.8974\n",
            "\n",
            " Training setup: Img:XGBoost | Txt:LogisticRegression | Tab:NaiveBayes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [05:30:51] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [05:30:51] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/core.py:2676: UserWarning: [05:31:14] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Img:XGBoost | Txt:LogisticRegression | Tab:NaiveBayes  Acc=0.8921, F1=0.8919\n",
            "\n",
            " Training setup: Img:XGBoost | Txt:NaiveBayes | Tab:XGBoost\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [05:32:03] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [05:32:03] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/core.py:2676: UserWarning: [05:32:26] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [05:32:38] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [05:32:38] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/core.py:2676: UserWarning: [05:32:40] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Img:XGBoost | Txt:NaiveBayes | Tab:XGBoost  Acc=0.8061, F1=0.8010\n",
            "\n",
            " Training setup: Img:XGBoost | Txt:NaiveBayes | Tab:LightGBM\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [05:32:57] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [05:32:57] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/core.py:2676: UserWarning: [05:33:20] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 81461, number of negative: 78725\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 562\n",
            "[LightGBM] [Info] Number of data points in the train set: 160186, number of used features: 3\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 3 dense feature groups (0.61 MB) transferred to GPU in 0.001539 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.508540 -> initscore=0.034164\n",
            "[LightGBM] [Info] Start training from score 0.034164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Img:XGBoost | Txt:NaiveBayes | Tab:LightGBM  Acc=0.8050, F1=0.7998\n",
            "\n",
            " Training setup: Img:XGBoost | Txt:NaiveBayes | Tab:LogisticRegression\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [05:34:01] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [05:34:01] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/core.py:2676: UserWarning: [05:34:24] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Img:XGBoost | Txt:NaiveBayes | Tab:LogisticRegression  Acc=0.7938, F1=0.7876\n",
            "\n",
            " Training setup: Img:XGBoost | Txt:NaiveBayes | Tab:NaiveBayes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [05:34:54] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [05:34:54] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/core.py:2676: UserWarning: [05:35:17] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Img:XGBoost | Txt:NaiveBayes | Tab:NaiveBayes  Acc=0.7761, F1=0.7681\n",
            "\n",
            " Training setup: Img:LightGBM | Txt:XGBoost | Tab:XGBoost\n",
            "[LightGBM] [Info] Number of positive: 81461, number of negative: 78725\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 130560\n",
            "[LightGBM] [Info] Number of data points in the train set: 160186, number of used features: 512\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 512 dense feature groups (78.22 MB) transferred to GPU in 0.169331 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.508540 -> initscore=0.034164\n",
            "[LightGBM] [Info] Start training from score 0.034164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [05:38:07] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [05:38:07] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/core.py:2676: UserWarning: [05:38:31] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [05:38:31] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [05:38:31] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/core.py:2676: UserWarning: [05:38:32] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Img:LightGBM | Txt:XGBoost | Tab:XGBoost  Acc=0.9118, F1=0.9118\n",
            "\n",
            " Training setup: Img:LightGBM | Txt:XGBoost | Tab:LightGBM\n",
            "[LightGBM] [Info] Number of positive: 81461, number of negative: 78725\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 130560\n",
            "[LightGBM] [Info] Number of data points in the train set: 160186, number of used features: 512\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 512 dense feature groups (78.22 MB) transferred to GPU in 0.297412 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.508540 -> initscore=0.034164\n",
            "[LightGBM] [Info] Start training from score 0.034164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [05:41:10] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [05:41:10] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/core.py:2676: UserWarning: [05:41:33] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 81461, number of negative: 78725\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 562\n",
            "[LightGBM] [Info] Number of data points in the train set: 160186, number of used features: 3\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 3 dense feature groups (0.61 MB) transferred to GPU in 0.001481 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.508540 -> initscore=0.034164\n",
            "[LightGBM] [Info] Start training from score 0.034164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Img:LightGBM | Txt:XGBoost | Tab:LightGBM  Acc=0.9115, F1=0.9115\n",
            "\n",
            " Training setup: Img:LightGBM | Txt:XGBoost | Tab:LogisticRegression\n",
            "[LightGBM] [Info] Number of positive: 81461, number of negative: 78725\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 130560\n",
            "[LightGBM] [Info] Number of data points in the train set: 160186, number of used features: 512\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 512 dense feature groups (78.22 MB) transferred to GPU in 0.159659 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.508540 -> initscore=0.034164\n",
            "[LightGBM] [Info] Start training from score 0.034164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [05:44:19] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [05:44:19] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/core.py:2676: UserWarning: [05:44:42] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Img:LightGBM | Txt:XGBoost | Tab:LogisticRegression  Acc=0.9022, F1=0.9021\n",
            "\n",
            " Training setup: Img:LightGBM | Txt:XGBoost | Tab:NaiveBayes\n",
            "[LightGBM] [Info] Number of positive: 81461, number of negative: 78725\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 130560\n",
            "[LightGBM] [Info] Number of data points in the train set: 160186, number of used features: 512\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 512 dense feature groups (78.22 MB) transferred to GPU in 0.153317 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.508540 -> initscore=0.034164\n",
            "[LightGBM] [Info] Start training from score 0.034164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [05:47:20] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [05:47:20] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/core.py:2676: UserWarning: [05:47:43] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Img:LightGBM | Txt:XGBoost | Tab:NaiveBayes  Acc=0.8983, F1=0.8982\n",
            "\n",
            " Training setup: Img:LightGBM | Txt:LightGBM | Tab:XGBoost\n",
            "[LightGBM] [Info] Number of positive: 81461, number of negative: 78725\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 130560\n",
            "[LightGBM] [Info] Number of data points in the train set: 160186, number of used features: 512\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 512 dense feature groups (78.22 MB) transferred to GPU in 0.317046 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.508540 -> initscore=0.034164\n",
            "[LightGBM] [Info] Start training from score 0.034164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 81461, number of negative: 78725\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 130560\n",
            "[LightGBM] [Info] Number of data points in the train set: 160186, number of used features: 512\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 512 dense feature groups (78.22 MB) transferred to GPU in 0.158177 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.508540 -> initscore=0.034164\n",
            "[LightGBM] [Info] Start training from score 0.034164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [05:52:22] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [05:52:22] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/core.py:2676: UserWarning: [05:52:23] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Img:LightGBM | Txt:LightGBM | Tab:XGBoost  Acc=0.9121, F1=0.9121\n",
            "\n",
            " Training setup: Img:LightGBM | Txt:LightGBM | Tab:LightGBM\n",
            "[LightGBM] [Info] Number of positive: 81461, number of negative: 78725\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 130560\n",
            "[LightGBM] [Info] Number of data points in the train set: 160186, number of used features: 512\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 512 dense feature groups (78.22 MB) transferred to GPU in 0.166082 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.508540 -> initscore=0.034164\n",
            "[LightGBM] [Info] Start training from score 0.034164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 81461, number of negative: 78725\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 130560\n",
            "[LightGBM] [Info] Number of data points in the train set: 160186, number of used features: 512\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 512 dense feature groups (78.22 MB) transferred to GPU in 0.150301 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.508540 -> initscore=0.034164\n",
            "[LightGBM] [Info] Start training from score 0.034164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 81461, number of negative: 78725\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 562\n",
            "[LightGBM] [Info] Number of data points in the train set: 160186, number of used features: 3\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 3 dense feature groups (0.61 MB) transferred to GPU in 0.002310 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.508540 -> initscore=0.034164\n",
            "[LightGBM] [Info] Start training from score 0.034164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Img:LightGBM | Txt:LightGBM | Tab:LightGBM  Acc=0.9114, F1=0.9113\n",
            "\n",
            " Training setup: Img:LightGBM | Txt:LightGBM | Tab:LogisticRegression\n",
            "[LightGBM] [Info] Number of positive: 81461, number of negative: 78725\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 130560\n",
            "[LightGBM] [Info] Number of data points in the train set: 160186, number of used features: 512\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 512 dense feature groups (78.22 MB) transferred to GPU in 0.155316 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.508540 -> initscore=0.034164\n",
            "[LightGBM] [Info] Start training from score 0.034164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 81461, number of negative: 78725\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 130560\n",
            "[LightGBM] [Info] Number of data points in the train set: 160186, number of used features: 512\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 512 dense feature groups (78.22 MB) transferred to GPU in 0.153243 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.508540 -> initscore=0.034164\n",
            "[LightGBM] [Info] Start training from score 0.034164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Img:LightGBM | Txt:LightGBM | Tab:LogisticRegression  Acc=0.9030, F1=0.9029\n",
            "\n",
            " Training setup: Img:LightGBM | Txt:LightGBM | Tab:NaiveBayes\n",
            "[LightGBM] [Info] Number of positive: 81461, number of negative: 78725\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 130560\n",
            "[LightGBM] [Info] Number of data points in the train set: 160186, number of used features: 512\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 512 dense feature groups (78.22 MB) transferred to GPU in 0.154050 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.508540 -> initscore=0.034164\n",
            "[LightGBM] [Info] Start training from score 0.034164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 81461, number of negative: 78725\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 130560\n",
            "[LightGBM] [Info] Number of data points in the train set: 160186, number of used features: 512\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 512 dense feature groups (78.22 MB) transferred to GPU in 0.153809 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.508540 -> initscore=0.034164\n",
            "[LightGBM] [Info] Start training from score 0.034164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Img:LightGBM | Txt:LightGBM | Tab:NaiveBayes  Acc=0.8975, F1=0.8974\n",
            "\n",
            " Training setup: Img:LightGBM | Txt:LogisticRegression | Tab:XGBoost\n",
            "[LightGBM] [Info] Number of positive: 81461, number of negative: 78725\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 130560\n",
            "[LightGBM] [Info] Number of data points in the train set: 160186, number of used features: 512\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 512 dense feature groups (78.22 MB) transferred to GPU in 0.164086 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.508540 -> initscore=0.034164\n",
            "[LightGBM] [Info] Start training from score 0.034164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [06:09:04] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [06:09:04] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/core.py:2676: UserWarning: [06:09:06] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Img:LightGBM | Txt:LogisticRegression | Tab:XGBoost  Acc=0.9070, F1=0.9069\n",
            "\n",
            " Training setup: Img:LightGBM | Txt:LogisticRegression | Tab:LightGBM\n",
            "[LightGBM] [Info] Number of positive: 81461, number of negative: 78725\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 130560\n",
            "[LightGBM] [Info] Number of data points in the train set: 160186, number of used features: 512\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 512 dense feature groups (78.22 MB) transferred to GPU in 0.327547 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.508540 -> initscore=0.034164\n",
            "[LightGBM] [Info] Start training from score 0.034164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 81461, number of negative: 78725\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 562\n",
            "[LightGBM] [Info] Number of data points in the train set: 160186, number of used features: 3\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 3 dense feature groups (0.61 MB) transferred to GPU in 0.001511 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.508540 -> initscore=0.034164\n",
            "[LightGBM] [Info] Start training from score 0.034164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Img:LightGBM | Txt:LogisticRegression | Tab:LightGBM  Acc=0.9071, F1=0.9070\n",
            "\n",
            " Training setup: Img:LightGBM | Txt:LogisticRegression | Tab:LogisticRegression\n",
            "[LightGBM] [Info] Number of positive: 81461, number of negative: 78725\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 130560\n",
            "[LightGBM] [Info] Number of data points in the train set: 160186, number of used features: 512\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 512 dense feature groups (78.22 MB) transferred to GPU in 0.318550 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.508540 -> initscore=0.034164\n",
            "[LightGBM] [Info] Start training from score 0.034164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Img:LightGBM | Txt:LogisticRegression | Tab:LogisticRegression  Acc=0.8976, F1=0.8975\n",
            "\n",
            " Training setup: Img:LightGBM | Txt:LogisticRegression | Tab:NaiveBayes\n",
            "[LightGBM] [Info] Number of positive: 81461, number of negative: 78725\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 130560\n",
            "[LightGBM] [Info] Number of data points in the train set: 160186, number of used features: 512\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 512 dense feature groups (78.22 MB) transferred to GPU in 0.151292 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.508540 -> initscore=0.034164\n",
            "[LightGBM] [Info] Start training from score 0.034164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Img:LightGBM | Txt:LogisticRegression | Tab:NaiveBayes  Acc=0.8920, F1=0.8918\n",
            "\n",
            " Training setup: Img:LightGBM | Txt:NaiveBayes | Tab:XGBoost\n",
            "[LightGBM] [Info] Number of positive: 81461, number of negative: 78725\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 130560\n",
            "[LightGBM] [Info] Number of data points in the train set: 160186, number of used features: 512\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 512 dense feature groups (78.22 MB) transferred to GPU in 0.155353 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.508540 -> initscore=0.034164\n",
            "[LightGBM] [Info] Start training from score 0.034164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [06:20:03] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [06:20:03] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/core.py:2676: UserWarning: [06:20:04] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Img:LightGBM | Txt:NaiveBayes | Tab:XGBoost  Acc=0.8049, F1=0.7997\n",
            "\n",
            " Training setup: Img:LightGBM | Txt:NaiveBayes | Tab:LightGBM\n",
            "[LightGBM] [Info] Number of positive: 81461, number of negative: 78725\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 130560\n",
            "[LightGBM] [Info] Number of data points in the train set: 160186, number of used features: 512\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 512 dense feature groups (78.22 MB) transferred to GPU in 0.155794 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.508540 -> initscore=0.034164\n",
            "[LightGBM] [Info] Start training from score 0.034164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 81461, number of negative: 78725\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 562\n",
            "[LightGBM] [Info] Number of data points in the train set: 160186, number of used features: 3\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 3 dense feature groups (0.61 MB) transferred to GPU in 0.001524 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.508540 -> initscore=0.034164\n",
            "[LightGBM] [Info] Start training from score 0.034164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Img:LightGBM | Txt:NaiveBayes | Tab:LightGBM  Acc=0.8037, F1=0.7984\n",
            "\n",
            " Training setup: Img:LightGBM | Txt:NaiveBayes | Tab:LogisticRegression\n",
            "[LightGBM] [Info] Number of positive: 81461, number of negative: 78725\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 130560\n",
            "[LightGBM] [Info] Number of data points in the train set: 160186, number of used features: 512\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 512 dense feature groups (78.22 MB) transferred to GPU in 0.148820 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.508540 -> initscore=0.034164\n",
            "[LightGBM] [Info] Start training from score 0.034164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Img:LightGBM | Txt:NaiveBayes | Tab:LogisticRegression  Acc=0.7922, F1=0.7859\n",
            "\n",
            " Training setup: Img:LightGBM | Txt:NaiveBayes | Tab:NaiveBayes\n",
            "[LightGBM] [Info] Number of positive: 81461, number of negative: 78725\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 130560\n",
            "[LightGBM] [Info] Number of data points in the train set: 160186, number of used features: 512\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 512 dense feature groups (78.22 MB) transferred to GPU in 0.150287 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.508540 -> initscore=0.034164\n",
            "[LightGBM] [Info] Start training from score 0.034164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Img:LightGBM | Txt:NaiveBayes | Tab:NaiveBayes  Acc=0.7747, F1=0.7665\n",
            "\n",
            " Training setup: Img:LogisticRegression | Txt:XGBoost | Tab:XGBoost\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [06:28:24] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [06:28:24] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/core.py:2676: UserWarning: [06:28:49] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [06:28:49] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [06:28:49] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/core.py:2676: UserWarning: [06:28:50] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Img:LogisticRegression | Txt:XGBoost | Tab:XGBoost  Acc=0.9107, F1=0.9106\n",
            "\n",
            " Training setup: Img:LogisticRegression | Txt:XGBoost | Tab:LightGBM\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [06:29:39] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [06:29:39] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/core.py:2676: UserWarning: [06:30:04] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 81461, number of negative: 78725\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 562\n",
            "[LightGBM] [Info] Number of data points in the train set: 160186, number of used features: 3\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 3 dense feature groups (0.61 MB) transferred to GPU in 0.001380 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.508540 -> initscore=0.034164\n",
            "[LightGBM] [Info] Start training from score 0.034164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Img:LogisticRegression | Txt:XGBoost | Tab:LightGBM  Acc=0.9106, F1=0.9106\n",
            "\n",
            " Training setup: Img:LogisticRegression | Txt:XGBoost | Tab:LogisticRegression\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [06:31:00] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [06:31:00] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/core.py:2676: UserWarning: [06:31:25] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Img:LogisticRegression | Txt:XGBoost | Tab:LogisticRegression  Acc=0.9020, F1=0.9019\n",
            "\n",
            " Training setup: Img:LogisticRegression | Txt:XGBoost | Tab:NaiveBayes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [06:32:12] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [06:32:12] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/core.py:2676: UserWarning: [06:32:36] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Img:LogisticRegression | Txt:XGBoost | Tab:NaiveBayes  Acc=0.8969, F1=0.8968\n",
            "\n",
            " Training setup: Img:LogisticRegression | Txt:LightGBM | Tab:XGBoost\n",
            "[LightGBM] [Info] Number of positive: 81461, number of negative: 78725\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 130560\n",
            "[LightGBM] [Info] Number of data points in the train set: 160186, number of used features: 512\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 512 dense feature groups (78.22 MB) transferred to GPU in 0.168154 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.508540 -> initscore=0.034164\n",
            "[LightGBM] [Info] Start training from score 0.034164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [06:35:23] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [06:35:23] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/core.py:2676: UserWarning: [06:35:24] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Img:LogisticRegression | Txt:LightGBM | Tab:XGBoost  Acc=0.9105, F1=0.9104\n",
            "\n",
            " Training setup: Img:LogisticRegression | Txt:LightGBM | Tab:LightGBM\n",
            "[LightGBM] [Info] Number of positive: 81461, number of negative: 78725\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 130560\n",
            "[LightGBM] [Info] Number of data points in the train set: 160186, number of used features: 512\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 512 dense feature groups (78.22 MB) transferred to GPU in 0.157814 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.508540 -> initscore=0.034164\n",
            "[LightGBM] [Info] Start training from score 0.034164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 81461, number of negative: 78725\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 562\n",
            "[LightGBM] [Info] Number of data points in the train set: 160186, number of used features: 3\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 3 dense feature groups (0.61 MB) transferred to GPU in 0.001508 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.508540 -> initscore=0.034164\n",
            "[LightGBM] [Info] Start training from score 0.034164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Img:LogisticRegression | Txt:LightGBM | Tab:LightGBM  Acc=0.9106, F1=0.9106\n",
            "\n",
            " Training setup: Img:LogisticRegression | Txt:LightGBM | Tab:LogisticRegression\n",
            "[LightGBM] [Info] Number of positive: 81461, number of negative: 78725\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 130560\n",
            "[LightGBM] [Info] Number of data points in the train set: 160186, number of used features: 512\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 512 dense feature groups (78.22 MB) transferred to GPU in 0.154001 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.508540 -> initscore=0.034164\n",
            "[LightGBM] [Info] Start training from score 0.034164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Img:LogisticRegression | Txt:LightGBM | Tab:LogisticRegression  Acc=0.9026, F1=0.9025\n",
            "\n",
            " Training setup: Img:LogisticRegression | Txt:LightGBM | Tab:NaiveBayes\n",
            "[LightGBM] [Info] Number of positive: 81461, number of negative: 78725\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 130560\n",
            "[LightGBM] [Info] Number of data points in the train set: 160186, number of used features: 512\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 512 dense feature groups (78.22 MB) transferred to GPU in 0.152403 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.508540 -> initscore=0.034164\n",
            "[LightGBM] [Info] Start training from score 0.034164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Img:LogisticRegression | Txt:LightGBM | Tab:NaiveBayes  Acc=0.8983, F1=0.8982\n",
            "\n",
            " Training setup: Img:LogisticRegression | Txt:LogisticRegression | Tab:XGBoost\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [06:44:50] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [06:44:50] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/core.py:2676: UserWarning: [06:44:51] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Img:LogisticRegression | Txt:LogisticRegression | Tab:XGBoost  Acc=0.9051, F1=0.9051\n",
            "\n",
            " Training setup: Img:LogisticRegression | Txt:LogisticRegression | Tab:LightGBM\n",
            "[LightGBM] [Info] Number of positive: 81461, number of negative: 78725\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 562\n",
            "[LightGBM] [Info] Number of data points in the train set: 160186, number of used features: 3\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 3 dense feature groups (0.61 MB) transferred to GPU in 0.001492 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.508540 -> initscore=0.034164\n",
            "[LightGBM] [Info] Start training from score 0.034164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Img:LogisticRegression | Txt:LogisticRegression | Tab:LightGBM  Acc=0.9049, F1=0.9048\n",
            "\n",
            " Training setup: Img:LogisticRegression | Txt:LogisticRegression | Tab:LogisticRegression\n",
            " Img:LogisticRegression | Txt:LogisticRegression | Tab:LogisticRegression  Acc=0.8973, F1=0.8973\n",
            "\n",
            " Training setup: Img:LogisticRegression | Txt:LogisticRegression | Tab:NaiveBayes\n",
            " Img:LogisticRegression | Txt:LogisticRegression | Tab:NaiveBayes  Acc=0.8920, F1=0.8918\n",
            "\n",
            " Training setup: Img:LogisticRegression | Txt:NaiveBayes | Tab:XGBoost\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [06:48:43] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [06:48:43] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/core.py:2676: UserWarning: [06:48:44] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Img:LogisticRegression | Txt:NaiveBayes | Tab:XGBoost  Acc=0.8015, F1=0.7959\n",
            "\n",
            " Training setup: Img:LogisticRegression | Txt:NaiveBayes | Tab:LightGBM\n",
            "[LightGBM] [Info] Number of positive: 81461, number of negative: 78725\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 562\n",
            "[LightGBM] [Info] Number of data points in the train set: 160186, number of used features: 3\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 3 dense feature groups (0.61 MB) transferred to GPU in 0.001377 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.508540 -> initscore=0.034164\n",
            "[LightGBM] [Info] Start training from score 0.034164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Img:LogisticRegression | Txt:NaiveBayes | Tab:LightGBM  Acc=0.8001, F1=0.7944\n",
            "\n",
            " Training setup: Img:LogisticRegression | Txt:NaiveBayes | Tab:LogisticRegression\n",
            " Img:LogisticRegression | Txt:NaiveBayes | Tab:LogisticRegression  Acc=0.7882, F1=0.7815\n",
            "\n",
            " Training setup: Img:LogisticRegression | Txt:NaiveBayes | Tab:NaiveBayes\n",
            " Img:LogisticRegression | Txt:NaiveBayes | Tab:NaiveBayes  Acc=0.7705, F1=0.7617\n",
            "\n",
            " Training setup: Img:NaiveBayes | Txt:XGBoost | Tab:XGBoost\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [06:51:27] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [06:51:27] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/core.py:2676: UserWarning: [06:51:52] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [06:51:52] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [06:51:52] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/core.py:2676: UserWarning: [06:51:53] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Img:NaiveBayes | Txt:XGBoost | Tab:XGBoost  Acc=0.7714, F1=0.7653\n",
            "\n",
            " Training setup: Img:NaiveBayes | Txt:XGBoost | Tab:LightGBM\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [06:52:22] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [06:52:22] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/core.py:2676: UserWarning: [06:52:46] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 81461, number of negative: 78725\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 562\n",
            "[LightGBM] [Info] Number of data points in the train set: 160186, number of used features: 3\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 3 dense feature groups (0.61 MB) transferred to GPU in 0.001469 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.508540 -> initscore=0.034164\n",
            "[LightGBM] [Info] Start training from score 0.034164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Img:NaiveBayes | Txt:XGBoost | Tab:LightGBM  Acc=0.7718, F1=0.7658\n",
            "\n",
            " Training setup: Img:NaiveBayes | Txt:XGBoost | Tab:LogisticRegression\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [06:53:26] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [06:53:26] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/core.py:2676: UserWarning: [06:53:51] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Img:NaiveBayes | Txt:XGBoost | Tab:LogisticRegression  Acc=0.7381, F1=0.7284\n",
            "\n",
            " Training setup: Img:NaiveBayes | Txt:XGBoost | Tab:NaiveBayes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [06:54:20] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [06:54:20] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/core.py:2676: UserWarning: [06:54:45] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Img:NaiveBayes | Txt:XGBoost | Tab:NaiveBayes  Acc=0.7283, F1=0.7178\n",
            "\n",
            " Training setup: Img:NaiveBayes | Txt:LightGBM | Tab:XGBoost\n",
            "[LightGBM] [Info] Number of positive: 81461, number of negative: 78725\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 130560\n",
            "[LightGBM] [Info] Number of data points in the train set: 160186, number of used features: 512\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 512 dense feature groups (78.22 MB) transferred to GPU in 0.148622 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.508540 -> initscore=0.034164\n",
            "[LightGBM] [Info] Start training from score 0.034164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [06:57:11] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [06:57:11] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/core.py:2676: UserWarning: [06:57:12] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Img:NaiveBayes | Txt:LightGBM | Tab:XGBoost  Acc=0.7687, F1=0.7624\n",
            "\n",
            " Training setup: Img:NaiveBayes | Txt:LightGBM | Tab:LightGBM\n",
            "[LightGBM] [Info] Number of positive: 81461, number of negative: 78725\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 130560\n",
            "[LightGBM] [Info] Number of data points in the train set: 160186, number of used features: 512\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 512 dense feature groups (78.22 MB) transferred to GPU in 0.151790 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.508540 -> initscore=0.034164\n",
            "[LightGBM] [Info] Start training from score 0.034164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 81461, number of negative: 78725\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 562\n",
            "[LightGBM] [Info] Number of data points in the train set: 160186, number of used features: 3\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 3 dense feature groups (0.61 MB) transferred to GPU in 0.001458 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.508540 -> initscore=0.034164\n",
            "[LightGBM] [Info] Start training from score 0.034164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Img:NaiveBayes | Txt:LightGBM | Tab:LightGBM  Acc=0.7680, F1=0.7616\n",
            "\n",
            " Training setup: Img:NaiveBayes | Txt:LightGBM | Tab:LogisticRegression\n",
            "[LightGBM] [Info] Number of positive: 81461, number of negative: 78725\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 130560\n",
            "[LightGBM] [Info] Number of data points in the train set: 160186, number of used features: 512\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 512 dense feature groups (78.22 MB) transferred to GPU in 0.322473 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.508540 -> initscore=0.034164\n",
            "[LightGBM] [Info] Start training from score 0.034164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Img:NaiveBayes | Txt:LightGBM | Tab:LogisticRegression  Acc=0.7346, F1=0.7245\n",
            "\n",
            " Training setup: Img:NaiveBayes | Txt:LightGBM | Tab:NaiveBayes\n",
            "[LightGBM] [Info] Number of positive: 81461, number of negative: 78725\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 130560\n",
            "[LightGBM] [Info] Number of data points in the train set: 160186, number of used features: 512\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 512 dense feature groups (78.22 MB) transferred to GPU in 0.149163 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.508540 -> initscore=0.034164\n",
            "[LightGBM] [Info] Start training from score 0.034164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Img:NaiveBayes | Txt:LightGBM | Tab:NaiveBayes  Acc=0.7247, F1=0.7135\n",
            "\n",
            " Training setup: Img:NaiveBayes | Txt:LogisticRegression | Tab:XGBoost\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [07:05:24] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [07:05:24] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/core.py:2676: UserWarning: [07:05:26] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Img:NaiveBayes | Txt:LogisticRegression | Tab:XGBoost  Acc=0.7585, F1=0.7512\n",
            "\n",
            " Training setup: Img:NaiveBayes | Txt:LogisticRegression | Tab:LightGBM\n",
            "[LightGBM] [Info] Number of positive: 81461, number of negative: 78725\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 562\n",
            "[LightGBM] [Info] Number of data points in the train set: 160186, number of used features: 3\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 3 dense feature groups (0.61 MB) transferred to GPU in 0.001456 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.508540 -> initscore=0.034164\n",
            "[LightGBM] [Info] Start training from score 0.034164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Img:NaiveBayes | Txt:LogisticRegression | Tab:LightGBM  Acc=0.7579, F1=0.7506\n",
            "\n",
            " Training setup: Img:NaiveBayes | Txt:LogisticRegression | Tab:LogisticRegression\n",
            " Img:NaiveBayes | Txt:LogisticRegression | Tab:LogisticRegression  Acc=0.7241, F1=0.7126\n",
            "\n",
            " Training setup: Img:NaiveBayes | Txt:LogisticRegression | Tab:NaiveBayes\n",
            " Img:NaiveBayes | Txt:LogisticRegression | Tab:NaiveBayes  Acc=0.7126, F1=0.7000\n",
            "\n",
            " Training setup: Img:NaiveBayes | Txt:NaiveBayes | Tab:XGBoost\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [07:08:02] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [07:08:02] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/core.py:2676: UserWarning: [07:08:04] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Img:NaiveBayes | Txt:NaiveBayes | Tab:XGBoost  Acc=0.8180, F1=0.8180\n",
            "\n",
            " Training setup: Img:NaiveBayes | Txt:NaiveBayes | Tab:LightGBM\n",
            "[LightGBM] [Info] Number of positive: 81461, number of negative: 78725\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 562\n",
            "[LightGBM] [Info] Number of data points in the train set: 160186, number of used features: 3\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 3 dense feature groups (0.61 MB) transferred to GPU in 0.001380 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.508540 -> initscore=0.034164\n",
            "[LightGBM] [Info] Start training from score 0.034164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Img:NaiveBayes | Txt:NaiveBayes | Tab:LightGBM  Acc=0.8173, F1=0.8173\n",
            "\n",
            " Training setup: Img:NaiveBayes | Txt:NaiveBayes | Tab:LogisticRegression\n",
            " Img:NaiveBayes | Txt:NaiveBayes | Tab:LogisticRegression  Acc=0.7873, F1=0.7873\n",
            "\n",
            " Training setup: Img:NaiveBayes | Txt:NaiveBayes | Tab:NaiveBayes\n",
            " Img:NaiveBayes | Txt:NaiveBayes | Tab:NaiveBayes  Acc=0.7787, F1=0.7786\n",
            "\n",
            " Best Late Fusion Configuration:\n",
            "Setup        Img:XGBoost | Txt:LightGBM | Tab:XGBoost\n",
            "Accuracy                                     0.912374\n",
            "Precision                                    0.913278\n",
            "Recall                                       0.912374\n",
            "F1                                           0.912298\n",
            "Name: 4, dtype: object\n",
            "\n",
            " Results saved and best configuration recorded to: /content/drive/MyDrive/results_local/multimodal_results.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.corr()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "F4XUbgxAd3zw",
        "outputId": "8d322070-4009-447a-b050-43af7437f6b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     upvote_ratio  2_way_label  num_comments_scaled  \\\n",
              "upvote_ratio             1.000000    -0.294226             0.116341   \n",
              "2_way_label             -0.294226     1.000000             0.270341   \n",
              "num_comments_scaled      0.116341     0.270341             1.000000   \n",
              "score_scaled             0.243826    -0.029932             0.557342   \n",
              "\n",
              "                     score_scaled  \n",
              "upvote_ratio             0.243826  \n",
              "2_way_label             -0.029932  \n",
              "num_comments_scaled      0.557342  \n",
              "score_scaled             1.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f57531c3-eb0f-4ec5-975f-6ed2a29a3e21\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>upvote_ratio</th>\n",
              "      <th>2_way_label</th>\n",
              "      <th>num_comments_scaled</th>\n",
              "      <th>score_scaled</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>upvote_ratio</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.294226</td>\n",
              "      <td>0.116341</td>\n",
              "      <td>0.243826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2_way_label</th>\n",
              "      <td>-0.294226</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.270341</td>\n",
              "      <td>-0.029932</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>num_comments_scaled</th>\n",
              "      <td>0.116341</td>\n",
              "      <td>0.270341</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.557342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>score_scaled</th>\n",
              "      <td>0.243826</td>\n",
              "      <td>-0.029932</td>\n",
              "      <td>0.557342</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f57531c3-eb0f-4ec5-975f-6ed2a29a3e21')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f57531c3-eb0f-4ec5-975f-6ed2a29a3e21 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f57531c3-eb0f-4ec5-975f-6ed2a29a3e21');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-c0039dcd-9f27-47a3-bb90-0f796ec82ffd\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c0039dcd-9f27-47a3-bb90-0f796ec82ffd')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-c0039dcd-9f27-47a3-bb90-0f796ec82ffd button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df_train\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"upvote_ratio\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.540215269475281,\n        \"min\": -0.2942260223172073,\n        \"max\": 1.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          -0.2942260223172073,\n          0.24382618052379315,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"2_way_label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.558788435551985,\n        \"min\": -0.2942260223172073,\n        \"max\": 1.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          1.0,\n          -0.029931899415302565,\n          -0.2942260223172073\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"num_comments_scaled\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.38834768939365405,\n        \"min\": 0.1163414545165577,\n        \"max\": 1.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.27034136140497345,\n          0.5573420989161582,\n          0.1163414545165577\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score_scaled\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.442213282498763,\n        \"min\": -0.029931899415302565,\n        \"max\": 1.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          -0.029931899415302565,\n          1.0,\n          0.24382618052379315\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "`# This is formatted as code`\n",
        "```\n",
        "\n",
        "without tabluar\n",
        "\"\"\"\n",
        "  Late fusion: trains multiple models per modality (image, text),\n",
        "  fuses predictions, and records metrics in Excel.\n",
        "   \"\"\""
      ],
      "metadata": {
        "id": "25D5UDSAfW0T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from lightgbm import LGBMClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "from openpyxl import Workbook, load_workbook\n",
        "from openpyxl.styles import Alignment, Font\n",
        "from openpyxl.utils import get_column_letter\n",
        "\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\" Using device: {device}\")\n",
        "\n",
        "\n",
        "def late_fusion_img_txt(\n",
        "    x_img_train, x_img_test,\n",
        "    x_txt_train, x_txt_test,\n",
        "    y_train, y_test,\n",
        "    excel_path=\"/content/drive/MyDrive/results_local/multimodal_results.xlsx\",\n",
        "    # fusion_weights=(0.5, 0.5)\n",
        "    fusion_weights=(0.5, 0.5)\n",
        "):\n",
        "    \"\"\"\n",
        "    Late fusion: trains multiple models per modality (image, text),\n",
        "    fuses predictions, and records metrics in Excel.\n",
        "    \"\"\"\n",
        "\n",
        "    # =======================\n",
        "    # DEFINE MODELS\n",
        "    # =======================\n",
        "    base_models = {\n",
        "        \"XGBoost\": XGBClassifier(\n",
        "            tree_method=\"gpu_hist\" if device == \"cuda\" else \"hist\",\n",
        "            gpu_id=0 if device == \"cuda\" else None,\n",
        "            use_label_encoder=False,\n",
        "            eval_metric=\"logloss\",\n",
        "            n_estimators=800,\n",
        "            learning_rate=0.05\n",
        "        ),\n",
        "        \"LightGBM\": LGBMClassifier(\n",
        "            n_estimators=1000, learning_rate=0.05,\n",
        "            device=\"gpu\" if device == \"cuda\" else \"cpu\"\n",
        "        ),\n",
        "        \"LogisticRegression\": LogisticRegression(max_iter=1000, solver=\"saga\", n_jobs=-1),\n",
        "        # \"NaiveBayes\": GaussianNB()\n",
        "    }\n",
        "\n",
        "    # =======================\n",
        "    # PREPARE EXCEL\n",
        "    # =======================\n",
        "    if os.path.exists(excel_path):\n",
        "        wb = load_workbook(excel_path)\n",
        "        ws = wb.active\n",
        "    else:\n",
        "        wb = Workbook()\n",
        "        ws = wb.active\n",
        "        ws.title = \"Late Fusion (Img+Txt)\"\n",
        "        ws.append([\"Fusion Setup\", \"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"])\n",
        "\n",
        "    w_img, w_txt = fusion_weights\n",
        "    results = []\n",
        "\n",
        "    # =======================\n",
        "    # TRAIN MODELS\n",
        "    # =======================\n",
        "    for img_name, img_model in base_models.items():\n",
        "        for txt_name, txt_model in base_models.items():\n",
        "            setup_name = f\"Img:{img_name} | Txt:{txt_name}\"\n",
        "            try:\n",
        "                print(f\"\\n Training setup: {setup_name}\")\n",
        "\n",
        "                # ---- Image model ----\n",
        "                img_model.fit(x_img_train, y_train)\n",
        "                img_pred = img_model.predict_proba(x_img_test)[:, 1]\n",
        "\n",
        "                # ---- Text model ----\n",
        "                txt_model.fit(x_txt_train, y_train)\n",
        "                txt_pred = txt_model.predict_proba(x_txt_test)[:, 1]\n",
        "\n",
        "                # ---- Late Fusion ----\n",
        "                fused_pred = (w_img * img_pred + w_txt * txt_pred)\n",
        "                fused_pred_label = (fused_pred >= 0.5).astype(int)\n",
        "\n",
        "                # ---- Metrics ----\n",
        "                acc = accuracy_score(y_test, fused_pred_label)\n",
        "                prec = precision_score(y_test, fused_pred_label, average='weighted', zero_division=0)\n",
        "                rec = recall_score(y_test, fused_pred_label, average='weighted', zero_division=0)\n",
        "                f1 = f1_score(y_test, fused_pred_label, average='weighted', zero_division=0)\n",
        "\n",
        "                results.append((setup_name, acc, prec, rec, f1))\n",
        "                ws.append([setup_name, acc, prec, rec, f1])\n",
        "                print(f\" {setup_name}  Acc={acc:.4f}, F1={f1:.4f}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\" Error in {setup_name}: {e}\")\n",
        "                ws.append([setup_name, \"ERROR\", \"ERROR\", \"ERROR\", \"ERROR\"])\n",
        "\n",
        "            wb.save(excel_path)\n",
        "\n",
        "    # =======================\n",
        "    # FIND BEST SETUP\n",
        "    # =======================\n",
        "    results_df = pd.DataFrame(results, columns=[\"Setup\", \"Accuracy\", \"Precision\", \"Recall\", \"F1\"])\n",
        "    best_row = results_df.loc[results_df[\"F1\"].idxmax()]\n",
        "    print(\"\\n Best Late Fusion Configuration:\")\n",
        "    print(best_row)\n",
        "\n",
        "    ws.append([])\n",
        "    ws.append([\"BEST MODEL\", best_row[\"Setup\"], best_row[\"Accuracy\"], best_row[\"Precision\"], best_row[\"Recall\"], best_row[\"F1\"]])\n",
        "    wb.save(excel_path)\n",
        "    print(f\"\\n Results saved and best configuration recorded to: {excel_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJSG3lgJfWMv",
        "outputId": "120e2c99-3150-4346-ab1b-365d658989ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "late_fusion_img_txt(\n",
        "    x_img_train, x_img_test,\n",
        "    x_txt_train, x_txt_test,\n",
        "    y_train, y_test,\n",
        "    excel_path=\"/content/drive/MyDrive/results_local/multimodal_results.xlsx\",\n",
        "    fusion_weights=(0.5, 0.5)  # try also (0.6, 0.4) or (0.7, 0.3)\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzBck6w8fxfe",
        "outputId": "dd1b6cce-8e36-45e7-8ca1-80b2ca74a7b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Training setup: Img:XGBoost | Txt:XGBoost\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [07:22:49] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [07:22:49] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/core.py:2676: UserWarning: [07:23:13] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [07:23:30] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [07:23:30] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/core.py:2676: UserWarning: [07:23:54] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Img:XGBoost | Txt:XGBoost  Acc=0.8915, F1=0.8914\n",
            "\n",
            " Training setup: Img:XGBoost | Txt:LightGBM\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [07:24:13] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [07:24:13] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/core.py:2676: UserWarning: [07:24:37] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 81461, number of negative: 78725\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 130560\n",
            "[LightGBM] [Info] Number of data points in the train set: 160186, number of used features: 512\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 512 dense feature groups (78.22 MB) transferred to GPU in 0.145896 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.508540 -> initscore=0.034164\n",
            "[LightGBM] [Info] Start training from score 0.034164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Img:XGBoost | Txt:LightGBM  Acc=0.8904, F1=0.8903\n",
            "\n",
            " Training setup: Img:XGBoost | Txt:LogisticRegression\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [07:27:08] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [07:27:08] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/core.py:2676: UserWarning: [07:27:32] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Img:XGBoost | Txt:LogisticRegression  Acc=0.8858, F1=0.8858\n",
            "\n",
            " Training setup: Img:LightGBM | Txt:XGBoost\n",
            "[LightGBM] [Info] Number of positive: 81461, number of negative: 78725\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 130560\n",
            "[LightGBM] [Info] Number of data points in the train set: 160186, number of used features: 512\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 512 dense feature groups (78.22 MB) transferred to GPU in 0.331621 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.508540 -> initscore=0.034164\n",
            "[LightGBM] [Info] Start training from score 0.034164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [07:30:30] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [07:30:30] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/core.py:2676: UserWarning: [07:30:55] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Img:LightGBM | Txt:XGBoost  Acc=0.8930, F1=0.8929\n",
            "\n",
            " Training setup: Img:LightGBM | Txt:LightGBM\n",
            "[LightGBM] [Info] Number of positive: 81461, number of negative: 78725\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 130560\n",
            "[LightGBM] [Info] Number of data points in the train set: 160186, number of used features: 512\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 512 dense feature groups (78.22 MB) transferred to GPU in 0.151280 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.508540 -> initscore=0.034164\n",
            "[LightGBM] [Info] Start training from score 0.034164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 81461, number of negative: 78725\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 130560\n",
            "[LightGBM] [Info] Number of data points in the train set: 160186, number of used features: 512\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 512 dense feature groups (78.22 MB) transferred to GPU in 0.169389 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.508540 -> initscore=0.034164\n",
            "[LightGBM] [Info] Start training from score 0.034164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Img:LightGBM | Txt:LightGBM  Acc=0.8925, F1=0.8924\n",
            "\n",
            " Training setup: Img:LightGBM | Txt:LogisticRegression\n",
            "[LightGBM] [Info] Number of positive: 81461, number of negative: 78725\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 130560\n",
            "[LightGBM] [Info] Number of data points in the train set: 160186, number of used features: 512\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 512 dense feature groups (78.22 MB) transferred to GPU in 0.150624 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.508540 -> initscore=0.034164\n",
            "[LightGBM] [Info] Start training from score 0.034164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Img:LightGBM | Txt:LogisticRegression  Acc=0.8855, F1=0.8854\n",
            "\n",
            " Training setup: Img:LogisticRegression | Txt:XGBoost\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [07:38:51] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [07:38:51] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/core.py:2676: UserWarning: [07:39:16] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Img:LogisticRegression | Txt:XGBoost  Acc=0.8911, F1=0.8910\n",
            "\n",
            " Training setup: Img:LogisticRegression | Txt:LightGBM\n",
            "[LightGBM] [Info] Number of positive: 81461, number of negative: 78725\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 130560\n",
            "[LightGBM] [Info] Number of data points in the train set: 160186, number of used features: 512\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 512 dense feature groups (78.22 MB) transferred to GPU in 0.146382 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.508540 -> initscore=0.034164\n",
            "[LightGBM] [Info] Start training from score 0.034164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Img:LogisticRegression | Txt:LightGBM  Acc=0.8914, F1=0.8913\n",
            "\n",
            " Training setup: Img:LogisticRegression | Txt:LogisticRegression\n",
            " Img:LogisticRegression | Txt:LogisticRegression  Acc=0.8848, F1=0.8847\n",
            "\n",
            " Best Late Fusion Configuration:\n",
            "Setup        Img:LightGBM | Txt:XGBoost\n",
            "Accuracy                       0.892968\n",
            "Precision                      0.893756\n",
            "Recall                         0.892968\n",
            "F1                             0.892881\n",
            "Name: 3, dtype: object\n",
            "\n",
            " Results saved and best configuration recorded to: /content/drive/MyDrive/results_local/multimodal_results.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "diffent weights\n",
        "\"\"\"\n",
        "    Late fusion with fixed models:\n",
        "      Img: XGBoost\n",
        "      Txt: LightGBM\n",
        "      Tab: XGBoost\n",
        "    Evaluates multiple fusion weight combinations and saves results to Excel.\n",
        "    \"\"\""
      ],
      "metadata": {
        "id": "AfeMlPyDmBBI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from openpyxl import Workbook, load_workbook\n",
        "\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\" Using device: {device}\")\n",
        "\n",
        "\n",
        "def late_fusion_fixed_models_weight_search(\n",
        "    x_img_train, x_img_test,\n",
        "    x_txt_train, x_txt_test,\n",
        "    x_tab_train, x_tab_test,\n",
        "    y_train, y_test,\n",
        "    excel_path=\"/content/drive/MyDrive/results_local/multimodal_results.xlsx\",\n",
        "    weight_grid=[\n",
        "        (0.4, 0.4, 0.2),\n",
        "        (0.5, 0.4, 0.1),\n",
        "        (0.6, 0.3, 0.1),\n",
        "        (0.5, 0.3, 0.2),\n",
        "        (0.3, 0.5, 0.2),\n",
        "        (0.4, 0.3, 0.3)\n",
        "    ]\n",
        "):\n",
        "    \"\"\"\n",
        "    Late fusion with fixed models:\n",
        "      Img: XGBoost\n",
        "      Txt: LightGBM\n",
        "      Tab: XGBoost\n",
        "    Evaluates multiple fusion weight combinations and saves results to Excel.\n",
        "    \"\"\"\n",
        "\n",
        "    # =======================\n",
        "    # DEFINE FIXED MODELS\n",
        "    # =======================\n",
        "    model_img = XGBClassifier(\n",
        "        tree_method=\"gpu_hist\" if device == \"cuda\" else \"hist\",\n",
        "        gpu_id=0 if device == \"cuda\" else None,\n",
        "        use_label_encoder=False,\n",
        "        eval_metric=\"logloss\",\n",
        "        n_estimators=800,\n",
        "        learning_rate=0.05\n",
        "    )\n",
        "\n",
        "    model_txt = LGBMClassifier(\n",
        "        n_estimators=1000, learning_rate=0.05,\n",
        "        device=\"gpu\" if device == \"cuda\" else \"cpu\"\n",
        "    )\n",
        "\n",
        "    model_tab = XGBClassifier(\n",
        "        tree_method=\"gpu_hist\" if device == \"cuda\" else \"hist\",\n",
        "        gpu_id=0 if device == \"cuda\" else None,\n",
        "        use_label_encoder=False,\n",
        "        eval_metric=\"logloss\",\n",
        "        n_estimators=800,\n",
        "        learning_rate=0.05\n",
        "    )\n",
        "\n",
        "    # =======================\n",
        "    # TRAIN ALL MODELS\n",
        "    # =======================\n",
        "    print(\"\\n Training models...\")\n",
        "\n",
        "    model_img.fit(x_img_train, y_train)\n",
        "    img_pred = model_img.predict_proba(x_img_test)[:, 1]\n",
        "\n",
        "    model_txt.fit(x_txt_train, y_train)\n",
        "    txt_pred = model_txt.predict_proba(x_txt_test)[:, 1]\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    x_tab_train_scaled = scaler.fit_transform(x_tab_train)\n",
        "    x_tab_test_scaled = scaler.transform(x_tab_test)\n",
        "    model_tab.fit(x_tab_train_scaled, y_train)\n",
        "    tab_pred = model_tab.predict_proba(x_tab_test_scaled)[:, 1]\n",
        "\n",
        "    # =======================\n",
        "    # PREPARE EXCEL\n",
        "    # =======================\n",
        "    if os.path.exists(excel_path):\n",
        "        wb = load_workbook(excel_path)\n",
        "        ws = wb.active\n",
        "    else:\n",
        "        wb = Workbook()\n",
        "        ws = wb.active\n",
        "        ws.title = \"Late Fusion (Fixed Models)\"\n",
        "        ws.append([\"Weights (Img,Txt,Tab)\", \"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"])\n",
        "\n",
        "    # =======================\n",
        "    # TEST MULTIPLE WEIGHTS\n",
        "    # =======================\n",
        "    results = []\n",
        "\n",
        "    print(\"\\n Testing fusion weight combinations...\")\n",
        "    for (w_img, w_txt, w_tab) in weight_grid:\n",
        "        fused_pred = (w_img * img_pred + w_txt * txt_pred + w_tab * tab_pred)\n",
        "        fused_label = (fused_pred >= 0.5).astype(int)\n",
        "\n",
        "        acc = accuracy_score(y_test, fused_label)\n",
        "        prec = precision_score(y_test, fused_label, average='weighted', zero_division=0)\n",
        "        rec = recall_score(y_test, fused_label, average='weighted', zero_division=0)\n",
        "        f1 = f1_score(y_test, fused_label, average='weighted', zero_division=0)\n",
        "\n",
        "        results.append(((w_img, w_txt, w_tab), acc, prec, rec, f1))\n",
        "        ws.append([f\"({w_img:.1f},{w_txt:.1f},{w_tab:.1f})\", acc, prec, rec, f1])\n",
        "        print(f\" Weights ({w_img:.1f},{w_txt:.1f},{w_tab:.1f})  Acc={acc:.4f}, F1={f1:.4f}\")\n",
        "\n",
        "        wb.save(excel_path)\n",
        "\n",
        "    # =======================\n",
        "    # FIND BEST WEIGHT COMBINATION\n",
        "    # =======================\n",
        "    results_df = pd.DataFrame(results, columns=[\"Weights\", \"Accuracy\", \"Precision\", \"Recall\", \"F1\"])\n",
        "    best_row = results_df.loc[results_df[\"F1\"].idxmax()]\n",
        "    print(\"\\n Best Fusion Weights:\")\n",
        "    print(best_row)\n",
        "\n",
        "    ws.append([])\n",
        "    ws.append([\"BEST WEIGHTS\", str(best_row[\"Weights\"]), best_row[\"Accuracy\"],\n",
        "               best_row[\"Precision\"], best_row[\"Recall\"], best_row[\"F1\"]])\n",
        "    wb.save(excel_path)\n",
        "    print(f\"\\n Results saved to: {excel_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TbBjHIcVmCbm",
        "outputId": "c1469eb1-67ab-43df-df05-2d5045dd335e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "late_fusion_fixed_models_weight_search(\n",
        "    x_img_train, x_img_test,\n",
        "    x_txt_train, x_txt_test,\n",
        "    df_train[['num_comments_scaled', 'score_scaled', 'upvote_ratio']],\n",
        "    df_test[['num_comments_scaled', 'score_scaled', 'upvote_ratio']],\n",
        "    y_train, y_test,\n",
        "    weight_grid=[\n",
        "        (0.4, 0.4, 0.2),\n",
        "        (0.5, 0.4, 0.1),\n",
        "        (0.6, 0.3, 0.1),\n",
        "        (0.5, 0.3, 0.2),\n",
        "        (0.3, 0.5, 0.2),\n",
        "        (0.4, 0.3, 0.3)\n",
        "    ]\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pR0aoeZpmgNx",
        "outputId": "bd4235b6-8a95-4692-c35e-c8ae6f046a30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Training models...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [07:51:58] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [07:51:58] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/core.py:2676: UserWarning: [07:52:23] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 81461, number of negative: 78725\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 130560\n",
            "[LightGBM] [Info] Number of data points in the train set: 160186, number of used features: 512\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 512 dense feature groups (78.22 MB) transferred to GPU in 0.145040 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.508540 -> initscore=0.034164\n",
            "[LightGBM] [Info] Start training from score 0.034164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [07:54:35] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [07:54:35] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/core.py:2676: UserWarning: [07:54:37] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Testing fusion weight combinations...\n",
            " Weights (0.4,0.4,0.2)  Acc=0.9124, F1=0.9123\n",
            " Weights (0.5,0.4,0.1)  Acc=0.9004, F1=0.9003\n",
            " Weights (0.6,0.3,0.1)  Acc=0.8875, F1=0.8873\n",
            " Weights (0.5,0.3,0.2)  Acc=0.9039, F1=0.9038\n",
            " Weights (0.3,0.5,0.2)  Acc=0.9075, F1=0.9074\n",
            " Weights (0.4,0.3,0.3)  Acc=0.9163, F1=0.9162\n",
            "\n",
            " Best Fusion Weights:\n",
            "Weights      (0.4, 0.3, 0.3)\n",
            "Accuracy            0.916267\n",
            "Precision           0.917314\n",
            "Recall              0.916267\n",
            "F1                  0.916186\n",
            "Name: 5, dtype: object\n",
            "\n",
            " Results saved to: /content/drive/MyDrive/results_local/multimodal_results.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "    Hybrid Fusion: Early (Image+Text) + Late (Tabular)\n",
        "    Image  LightGBM | Text  XGBoost | Tabular  LogisticRegression/XGBoost"
      ],
      "metadata": {
        "id": "0N3bBIV6V-wT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch, gc\n",
        "\n",
        "from lightgbm import LGBMClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from openpyxl import Workbook, load_workbook\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\" Using device: {device}\")\n",
        "\n",
        "\n",
        "def safe_train(model, X, y, desc=\"\"):\n",
        "    \"\"\"Train model safely with GPUCPU fallback if OOM occurs.\"\"\"\n",
        "    try:\n",
        "        print(f\" Training {desc} on {device.upper()} ...\")\n",
        "        model.fit(X, y)\n",
        "    except Exception as e:\n",
        "        if \"CUDA\" in str(e) or \"GPU\" in str(e):\n",
        "            print(f\" GPU OOM while training {desc}, switching to CPU ...\")\n",
        "            if isinstance(model, XGBClassifier):\n",
        "                model.set_params(device=\"cpu\")\n",
        "            elif isinstance(model, LGBMClassifier):\n",
        "                model.set_params(device=\"cpu\")\n",
        "            model.fit(X, y)\n",
        "        else:\n",
        "            raise e\n",
        "    gc.collect()\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "    print(f\" Finished {desc}\")\n",
        "    return model\n",
        "\n",
        "\n",
        "def hybrid_fusion_imgtxt_tab_safe(\n",
        "    x_img_train, x_img_test,\n",
        "    x_txt_train, x_txt_test,\n",
        "    x_tab_train, x_tab_test,\n",
        "    y_train, y_test,\n",
        "    excel_path=\"/content/drive/MyDrive/results_local/multimodal_results.xlsx\",\n",
        "    fusion_weights=[(0.5, 0.5), (0.6, 0.4), (0.7, 0.3), (0.4, 0.6)]\n",
        "):\n",
        "    \"\"\"\n",
        "    Hybrid Fusion: Early (Image+Text) + Late (Tabular)\n",
        "    Image  LightGBM | Text  XGBoost | Tabular  LogisticRegression/XGBoost\n",
        "    \"\"\"\n",
        "\n",
        "    # ======================================================\n",
        "    # 1 Train Image + Text models (Early Fusion)\n",
        "    # ======================================================\n",
        "    print(\"\\n Training Image (LightGBM) and Text (XGBoost) models...\")\n",
        "\n",
        "    model_img = LGBMClassifier(\n",
        "        n_estimators=600, learning_rate=0.05,\n",
        "        device=\"gpu\" if device == \"cuda\" else \"cpu\"\n",
        "    )\n",
        "    model_txt = XGBClassifier(\n",
        "        tree_method=\"hist\",\n",
        "        device=\"cuda\" if device == \"cuda\" else \"cpu\",\n",
        "        eval_metric=\"logloss\",\n",
        "        n_estimators=600,\n",
        "        learning_rate=0.05\n",
        "    )\n",
        "\n",
        "    model_img = safe_train(model_img, x_img_train, y_train, \"LightGBM (Image)\")\n",
        "    img_pred = model_img.predict_proba(x_img_test)[:, 1]\n",
        "\n",
        "    model_txt = safe_train(model_txt, x_txt_train, y_train, \"XGBoost (Text)\")\n",
        "    txt_pred = model_txt.predict_proba(x_txt_test)[:, 1]\n",
        "\n",
        "    # Early fusion prediction\n",
        "    early_fused_pred = 0.5 * img_pred + 0.5 * txt_pred\n",
        "    del img_pred, txt_pred\n",
        "    gc.collect()\n",
        "    if torch.cuda.is_available(): torch.cuda.empty_cache()\n",
        "\n",
        "    # ======================================================\n",
        "    # 2 Train Tabular Models\n",
        "    # ======================================================\n",
        "    print(\"\\n Training Tabular models (LogisticRegression, XGBoost)...\")\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    x_tab_train_scaled = scaler.fit_transform(x_tab_train)\n",
        "    x_tab_test_scaled = scaler.transform(x_tab_test)\n",
        "\n",
        "    tab_models = {\n",
        "        \"LogisticRegression\": LogisticRegression(max_iter=1000, solver=\"saga\", n_jobs=-1),\n",
        "        \"XGBoost\": XGBClassifier(\n",
        "            tree_method=\"hist\",\n",
        "            device=\"cuda\" if device == \"cuda\" else \"cpu\",\n",
        "            eval_metric=\"logloss\",\n",
        "            n_estimators=600,\n",
        "            learning_rate=0.05\n",
        "        )\n",
        "    }\n",
        "\n",
        "    # ======================================================\n",
        "    # 3 Late Fusion Evaluation\n",
        "    # ======================================================\n",
        "    if os.path.exists(excel_path):\n",
        "        wb = load_workbook(excel_path)\n",
        "        ws = wb.active\n",
        "    else:\n",
        "        wb = Workbook()\n",
        "        ws = wb.active\n",
        "        ws.title = \"Hybrid Fusion Safe\"\n",
        "        ws.append([\"Tab Model\", \"Weights (Early,Tab)\", \"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"])\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for tab_name, tab_model in tab_models.items():\n",
        "        tab_model = safe_train(tab_model, x_tab_train_scaled, y_train, f\"Tabular ({tab_name})\")\n",
        "        tab_pred = tab_model.predict_proba(x_tab_test_scaled)[:, 1]\n",
        "\n",
        "        for (w_early, w_tab) in fusion_weights:\n",
        "            fused_pred = w_early * early_fused_pred + w_tab * tab_pred\n",
        "            fused_label = (fused_pred >= 0.5).astype(int)\n",
        "\n",
        "            acc = accuracy_score(y_test, fused_label)\n",
        "            prec = precision_score(y_test, fused_label, average='weighted', zero_division=0)\n",
        "            rec = recall_score(y_test, fused_label, average='weighted', zero_division=0)\n",
        "            f1 = f1_score(y_test, fused_label, average='weighted', zero_division=0)\n",
        "\n",
        "            results.append((tab_name, (w_early, w_tab), acc, prec, rec, f1))\n",
        "            ws.append([tab_name, f\"({w_early:.1f},{w_tab:.1f})\", acc, prec, rec, f1])\n",
        "            wb.save(excel_path)\n",
        "            print(f\" {tab_name} | Weights ({w_early:.1f},{w_tab:.1f})  Acc={acc:.4f}, F1={f1:.4f}\")\n",
        "\n",
        "        del tab_model, tab_pred\n",
        "        gc.collect()\n",
        "        if torch.cuda.is_available(): torch.cuda.empty_cache()\n",
        "\n",
        "    # ======================================================\n",
        "    # 4 Best Configuration\n",
        "    # ======================================================\n",
        "    results_df = pd.DataFrame(results, columns=[\"Tab Model\", \"Weights\", \"Accuracy\", \"Precision\", \"Recall\", \"F1\"])\n",
        "    best_row = results_df.loc[results_df[\"F1\"].idxmax()]\n",
        "    print(\"\\n Best Hybrid Fusion Configuration:\")\n",
        "    print(best_row)\n",
        "\n",
        "    ws.append([])\n",
        "    ws.append([\"BEST HYBRID\", f\"{best_row['Tab Model']}\", str(best_row[\"Weights\"]),\n",
        "               best_row[\"Accuracy\"], best_row[\"Precision\"], best_row[\"Recall\"], best_row[\"F1\"]])\n",
        "    wb.save(excel_path)\n",
        "    print(f\"\\n Results saved to: {excel_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92R6V1ufpjJT",
        "outputId": "57f79fb7-a0c9-445b-b77f-71c4c98d6077"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hybrid_fusion_imgtxt_tab_safe(\n",
        "    x_img_train, x_img_test,\n",
        "    x_txt_train, x_txt_test,\n",
        "    df_train[['num_comments_scaled', 'score_scaled', 'upvote_ratio']],\n",
        "    df_test[['num_comments_scaled', 'score_scaled', 'upvote_ratio']],\n",
        "    y_train, y_test,\n",
        "    fusion_weights=[(0.5, 0.5), (0.6, 0.4), (0.7, 0.3)]\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3otth1vLpm_R",
        "outputId": "25307212-aa5a-47ad-c8c2-31af8f7dbde8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Training Image (LightGBM) and Text (XGBoost) models...\n",
            " Training LightGBM (Image) on CUDA ...\n",
            "[LightGBM] [Info] Number of positive: 81461, number of negative: 78725\n",
            "[LightGBM] [Info] This is the GPU trainer!!\n",
            "[LightGBM] [Info] Total Bins 130560\n",
            "[LightGBM] [Info] Number of data points in the train set: 160186, number of used features: 512\n",
            "[LightGBM] [Info] Using GPU Device: Tesla T4, Vendor: NVIDIA Corporation\n",
            "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
            "[LightGBM] [Info] GPU programs have been built\n",
            "[LightGBM] [Info] Size of histogram bin entry: 8\n",
            "[LightGBM] [Info] 512 dense feature groups (78.22 MB) transferred to GPU in 0.151299 secs. 0 sparse feature groups\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.508540 -> initscore=0.034164\n",
            "[LightGBM] [Info] Start training from score 0.034164\n",
            " Finished LightGBM (Image)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Training XGBoost (Text) on CUDA ...\n",
            " Finished XGBoost (Text)\n",
            "\n",
            " Training Tabular models (LogisticRegression, XGBoost)...\n",
            " Training Tabular (LogisticRegression) on CUDA ...\n",
            " Finished Tabular (LogisticRegression)\n",
            " LogisticRegression | Weights (0.5,0.5)  Acc=0.8954, F1=0.8953\n",
            " LogisticRegression | Weights (0.6,0.4)  Acc=0.9027, F1=0.9026\n",
            " LogisticRegression | Weights (0.7,0.3)  Acc=0.9026, F1=0.9024\n",
            " Training Tabular (XGBoost) on CUDA ...\n",
            " Finished Tabular (XGBoost)\n",
            " XGBoost | Weights (0.5,0.5)  Acc=0.9115, F1=0.9114\n",
            " XGBoost | Weights (0.6,0.4)  Acc=0.9184, F1=0.9183\n",
            " XGBoost | Weights (0.7,0.3)  Acc=0.9166, F1=0.9165\n",
            "\n",
            " Best Hybrid Fusion Configuration:\n",
            "Tab Model       XGBoost\n",
            "Weights      (0.6, 0.4)\n",
            "Accuracy       0.918364\n",
            "Precision      0.919184\n",
            "Recall         0.918364\n",
            "F1             0.918299\n",
            "Name: 4, dtype: object\n",
            "\n",
            " Results saved to: /content/drive/MyDrive/results_local/multimodal_results.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y4QjeibSv61y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3kfxV0NQv60O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NMrDIhJdv6yq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.decomposition import PCA\n",
        "\n",
        "# pca_dim = 256  # can test 128, 256, 384\n",
        "# pca_img = PCA(n_components=pca_dim, random_state=42)\n",
        "# pca_txt = PCA(n_components=pca_dim, random_state=42)\n",
        "\n",
        "# x_img_train_pca = pca_img.fit_transform(x_img_train)\n",
        "# x_img_test_pca  = pca_img.transform(x_img_test)\n",
        "# x_txt_train_pca = pca_txt.fit_transform(x_txt_train)\n",
        "# x_txt_test_pca  = pca_txt.transform(x_txt_test)\n"
      ],
      "metadata": {
        "id": "_h9cYrvYv6wt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w_img, w_txt = 0.55, 0.45\n",
        "\n",
        "X_train_fused = np.concatenate(\n",
        "    [x_img_train * w_img, x_txt_train * w_txt], axis=1\n",
        ")\n",
        "X_test_fused = np.concatenate(\n",
        "    [x_img_test * w_img, x_txt_test * w_txt], axis=1\n",
        ")\n",
        "\n",
        "print(\"Fused feature shape:\", X_train_fused.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAqB8jVywC3I",
        "outputId": "bc6a23df-dc99-4ec2-a21d-fd92492347b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fused feature shape: (160186, 1024)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_fused = scaler.fit_transform(X_train_fused)\n",
        "X_test_fused  = scaler.transform(X_test_fused)\n"
      ],
      "metadata": {
        "id": "yhUkS5N_wLDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_model = XGBClassifier(\n",
        "    n_estimators=1200,\n",
        "    learning_rate=0.02,\n",
        "    max_depth=10,\n",
        "    subsample=0.9,\n",
        "    colsample_bytree=0.8,\n",
        "    min_child_weight=1,\n",
        "    reg_lambda=1.0,\n",
        "    reg_alpha=0.1,\n",
        "    tree_method=\"hist\",\n",
        "    device=\"cuda\",\n",
        "    eval_metric=\"logloss\",\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n"
      ],
      "metadata": {
        "id": "qHKgu-LPwNnP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for w_img in [0.4, 0.45, 0.5]:\n",
        "    w_txt = 1 - w_img\n",
        "    # rebuild fusion, retrain, and record F1\n"
      ],
      "metadata": {
        "id": "JTUXDii7yBC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_prob = xgb_model.predict_proba(X_test_fused)[:, 1]\n",
        "y_pred = (y_prob >= 0.5).astype(int)\n",
        "\n",
        "acc  = accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "rec  = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "f1   = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "\n",
        "print(f\"\\n Tuned Early Fusion XGBoost Results:\")\n",
        "print(f\"Accuracy : {acc:.4f}\")\n",
        "print(f\"Precision: {prec:.4f}\")\n",
        "print(f\"Recall   : {rec:.4f}\")\n",
        "print(f\"F1 Score : {f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QPjy2d1wZZa",
        "outputId": "fd19ad0b-3804-49c9-973d-41645811b1ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Tuned Early Fusion XGBoost Results:\n",
            "Accuracy : 0.9019\n",
            "Precision: 0.9023\n",
            "Recall   : 0.9019\n",
            "F1 Score : 0.9018\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gc\n",
        "import torch\n",
        "from xgboost import XGBClassifier, callback\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from openpyxl import Workbook\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 1 Scaling\n",
        "# --------------------------------------------------\n",
        "scaler_img = StandardScaler()\n",
        "scaler_txt = StandardScaler()\n",
        "\n",
        "x_img_train_s = scaler_img.fit_transform(x_img_train)\n",
        "x_img_test_s  = scaler_img.transform(x_img_test)\n",
        "x_txt_train_s = scaler_txt.fit_transform(x_txt_train)\n",
        "x_txt_test_s  = scaler_txt.transform(x_txt_test)\n",
        "\n",
        "# Optional PCA compression (for extra speed)\n",
        "\"\"\"\n",
        "from sklearn.decomposition import PCA\n",
        "pca_img = PCA(n_components=256, random_state=42)\n",
        "pca_txt = PCA(n_components=256, random_state=42)\n",
        "x_img_train_s = pca_img.fit_transform(x_img_train_s)\n",
        "x_img_test_s  = pca_img.transform(x_img_test_s)\n",
        "x_txt_train_s = pca_txt.fit_transform(x_txt_train_s)\n",
        "x_txt_test_s  = pca_txt.transform(x_txt_test_s)\n",
        "\"\"\"\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 2 Define fast GPU XGBoost model\n",
        "# --------------------------------------------------\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "def build_xgb():\n",
        "    return XGBClassifier(\n",
        "        n_estimators=1000,\n",
        "        learning_rate=0.03,\n",
        "        max_depth=8,\n",
        "        subsample=0.9,\n",
        "        colsample_bytree=0.8,\n",
        "        min_child_weight=1,\n",
        "        reg_lambda=1.0,\n",
        "        reg_alpha=0.1,\n",
        "        gamma=0.2,\n",
        "        tree_method=\"gpu_hist\",\n",
        "        predictor=\"gpu_predictor\",\n",
        "        eval_metric=\"logloss\",\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 3 Weighted early fusion (GPU + early stopping)\n",
        "# --------------------------------------------------\n",
        "weights_to_try = np.arange(0.3, 0.71, 0.05)\n",
        "results = []\n",
        "\n",
        "# Split a small validation set for early stopping\n",
        "X_train_img, X_val_img, X_train_txt, X_val_txt, y_train_split, y_val_split = train_test_split(\n",
        "    x_img_train_s, x_txt_train_s, y_train, test_size=0.15, random_state=42, stratify=y_train\n",
        ")\n",
        "\n",
        "for w_img in weights_to_try:\n",
        "    w_txt = 1 - w_img\n",
        "    print(f\"\\n Training with weights  Image: {w_img:.2f}, Text: {w_txt:.2f}\")\n",
        "\n",
        "    # Fuse embeddings\n",
        "    X_train_fused = np.concatenate([X_train_img * w_img, X_train_txt * w_txt], axis=1)\n",
        "    X_val_fused   = np.concatenate([X_val_img * w_img,   X_val_txt * w_txt], axis=1)\n",
        "    X_test_fused  = np.concatenate([x_img_test_s * w_img, x_txt_test_s * w_txt], axis=1)\n",
        "\n",
        "    # Build + train model (GPU + early stopping via callback)\n",
        "    model = build_xgb()\n",
        "    early_stop = callback.EarlyStopping(rounds=50, save_best=True, maximize=False)\n",
        "    model.fit(\n",
        "        X_train_fused,\n",
        "        y_train_split,\n",
        "        eval_set=[(X_val_fused, y_val_split)],\n",
        "        verbose=False,\n",
        "        callbacks=[early_stop]\n",
        "    )\n",
        "\n",
        "    # Predict on test set\n",
        "    y_pred = model.predict(X_test_fused)\n",
        "    acc  = accuracy_score(y_test, y_pred)\n",
        "    f1   = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "    prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "    rec  = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "\n",
        "    print(f\" F1={f1:.4f} | Acc={acc:.4f} | Prec={prec:.4f} | Rec={rec:.4f}\")\n",
        "\n",
        "    results.append({\n",
        "        \"w_img\": w_img, \"w_txt\": w_txt,\n",
        "        \"Acc\": acc, \"F1\": f1, \"Precision\": prec, \"Recall\": rec\n",
        "    })\n",
        "\n",
        "    # Free memory after each weight test\n",
        "    del model, X_train_fused, X_val_fused, X_test_fused\n",
        "    gc.collect()\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 4 Best configuration\n",
        "# --------------------------------------------------\n",
        "results_df = pd.DataFrame(results)\n",
        "best_row = results_df.loc[results_df[\"F1\"].idxmax()]\n",
        "\n",
        "print(\"\\n Best Early Fusion Configuration:\")\n",
        "print(best_row)\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 5 Save results\n",
        "# --------------------------------------------------\n",
        "excel_path = \"/content/drive/MyDrive/results_local/multimodal_results.xlsx\"\n",
        "\n",
        "wb = Workbook()\n",
        "ws = wb.active\n",
        "ws.title = \"Results\"\n",
        "\n",
        "# Headers\n",
        "ws.append(list(results_df.columns))\n",
        "for _, row in results_df.iterrows():\n",
        "    ws.append(row.tolist())\n",
        "\n",
        "ws.append([])\n",
        "ws.append([\"BEST CONFIG\"])\n",
        "for col, val in best_row.items():\n",
        "    ws.append([col, val])\n",
        "\n",
        "wb.save(excel_path)\n",
        "print(f\"\\n Results saved successfully to: {excel_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "id": "L7BMdsvsyWPg",
        "outputId": "9b9cb096-eba2-4c55-a55d-76fadb7e3a19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "\n",
            " Training with weights  Image: 0.30, Text: 0.70\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "XGBClassifier.fit() got an unexpected keyword argument 'callbacks'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3474393940.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_xgb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0mearly_stop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaximize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m     model.fit(\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0mX_train_fused\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0my_train_split\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    727\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: XGBClassifier.fit() got an unexpected keyword argument 'callbacks'"
          ]
        }
      ]
    }
  ]
}